
this is essentially a collection of program comments
that became so large they made the code hard to read,
so they were moved here for posterity.

the #! is used to provide some extra context to the
comment, because some of them are hard to understand
out of their code location.

Just enough to say what is interesting
  no more.


  -> make it work
  -> document how/why it works
  -> pay off technical debt
  -> make it work better or
  -> make it do another thing
  -> loop/iterate/recur


  events/captures -> analysis/reasoning -> views/storage

-------------------------------------------------------------------------------
what is a programming language composed of?
		-> state and behavior.

	what does a programming language need to talk about?
		-> itself and its environment

		divide the language into four quadrants
     (state <-> behavior, itself <-> environment)


        				|state				            | behavior
----------------|-------------------------|----------------------------
				        |	vars, constants	        |	functions
itself          |	internal context        |	function calls
				        |	new types		            |	primitive behaviors
----------------|-------------------------|------------------------
				        |	processor state         |	OS/library functions
environment	    |	OS state,		            |	other programs
				        |	Hardware state	        |	internal/external hardware.

		note:
			divide the language into four quadrants
      (primary <-> composed, concrete <-> abstract)

			      |	primary (an entity that cannot be decomposed			|	composed (an entity formed of primary and
			      |				at the current level of abstraction)		    |				composed entities)
------------|---------------------------------------------------|------------------------
			      |	functions&macros:		| atoms:						          |	function:			      	| atoms:
concrete	  |	=, +, *, cmpxchg,		|	int, real, text,			      |	  push, pop, peek,		|   stack, queue, list
 provided	  |	typeof, sizeof, [],	|	predefined constants		    |	  prepend, append,		|   map, set, file,
 by the		  |	if, while, print		|	[], *, !*,					        |	  open, seek, fork,		|   socket, thread,
 language	  |							        |								              |
------------|---------------------------------------------------|-------------------------
			      |	functions:				| atoms:						            |	function:				     | atoms:
abstract	  |	macro, fcall,			|	local & global vars,		      |	fn, \, 						   | type (adt),
 written	  |	 						      |								                | operator definitions |
 by the		  |							      |	local and global consts		    |
 programmer	|							      |							                	|

-------------------------------------------------------------------------------
#! language-philosophy

a + b c - d
-->> (+ a (- (b c) d))

b c d e * f g h i
-->> (* (b d c e) (f g h i))

a b + c d * e f - g h
-->> (+ (a b) (- (* (c d) (e f)) (g h))

these few expressions are what really
is the driving force behind what the language
is to me. if we consider the expressive power
of infix expressions plus function application.
we have arrived at some percentage of the
expressive power of both imperitive and functional languages.
this core is extended with subtyping, polymorphism,
modules/abstract types, concurrency, and more. but
the basic materia of a program are it's variables,
primitive operations, the ability to compose operations into expressions,
and functions, which abstract over those expressions.
if we give programmers the ability to describe a new
binary operators. we are in essence allowing
extension of the language. in exactly the same
way that defining a function is extending the language.
then, you ask why have both? because sometimes the infix
syntax is highly convenient, and application is a required
primitive. (infix expressions are also secretly 'just' applications)
it is already known that the basic unit of abstraction is the function.
(that is why we defined functions in the first place)
operations are then essentially the basic unit of work.
the set of primitive operations that a programmer has
access to is (sort-of) the entirety of the set of things that
they can to. anything that we want done that isn't one
of the primitive operations needs to be defined by the
programmer. it needs to be composed.
(which primitives are available has a
 profound effect on the shape of programs
 written in the language.)
(i say sort of, because the api surrounding operating
system primitives rides the defining line here)
expressions and function application are the
basic units of composition. by restricting
definitions to be known/computable at compile time
we can factor as much out of the runtime of the simplest
program as is reasonable. "only pay for what you use."
again because this language
is built to specify programs from the base materia.
we want to severely restrict the size and scope of
the kernel of the language. we want to give just enough
tools to say things in the best way we know how,
and then we build everything out of that.
it essentially defines the sandbox and the toolbox all in one.
now, we don't want to make a turing tar-pit.
so, we will have some standard library.
when something is a kernel feature vs a library one is a question
that still needs answering.


types and the type system is what maintains
the alignment between what expressions can validly
be stated by the grammar and what expressions can be
validly expressed by the runtime.

a + b c - d
-->> (+ a (- (b c) d))

b c d e * f g h i
-->> (* (b d c e) (f g h i))

a b + c d * e f - g h
-->> (+ (a b) (- (* (c d) (e f)) (g h))

(a binop b) (c binop d binop e)
-->>(binop a b) (binop c (binop d e))


--------------------------------------------------------------------------------
#! working out Procedures

how is it that we mean to support first class functions in a
procedural way? I'm like 99% sure that we don't want to give
life to the idea of constructing functions at runtime.
we want all function applications to be definable at compile-time.
then we can compile & link them, and bam, a program. this is
in my mind what it means to be C-like as opposed to functional
or object oriented, instead of having a lot of implicitly available
syntax (which adds to the size of a compiled program), Pink will
have a small but extensible core, to which a programmer can request
the addition of semantics. so, eventually there may be semantics
supporting some particular abstraction, but it would come by way
of being defined in the language itself, as opposed to being a part
of the language definition itself.

first, i suppose i should say what i mean when i say procedural programming,
I mean to imply the exact middle of the total intersection of
functional and imperative programming. allowing cohabitiation and collaboration
rather than confrontation and convolution.

so, again how is it that we mean to support first class functions
modulo the ability to define new functions at runtime? I think
some form of defunctionalization would work as a compilation technique.
formally this works by decomposing all higher order functions
into first order functions by introducing an implicit "apply" function
which collates all lambdas applied by a particular call site,
and then when the higher-order
function attempts to call it's procedure argument,
that can be supported by a call to the apply function
passing in the lambda closure. the apply function uses the
closure to select the correct first order definition to call,
and the closure is constructed by the defining scope of the lambda
to be (copies of pure variables, or later a reference) variables local
to the lambdas scope that are not a part of it's formal arguments,
(it's 'free' variables.)

this can be handled in assembly by constructing a tuple of the
closed over values and passing that tuple as the immediate next argument
to the lambda, as an implicit argument, then in the actual body, the
closure bindings are accessed through said argument. this tuple can be
allocated on the stack or the heap depending on the usage of said lambda.
the lambda for the downwards-funarg-problem can be stack allocated.
the tuple in the upwards-funarg-problem needs to be heap allocated.

what if instead of dispatching over a set of definitions
we pass a record  containing a function ptr, and the closure.
and the definition of the lambda expects the closure as an argument.
then, all some application needs to do, is call the function ptr,
passing in the closure followed by the actual arguments. the
'dispatch' can then be handled by the fact that a different
function ptr can be passed in via the first argument.
and any lambda being applied within a polymorphic function
already needs to maintain well-formedness by definition, so if
we are talking about some well formed application, every lambda
that can validly be passed as the argument, by definition, has
the same shaped formal argument list. (the polymorphic type
is plainly bound to some monomorphic type within some instance,
but for the application site to have passed the typechecker,
the lambda being passed in as an argument must be well-formed
when called by the polymorphic function, meaning whatever
monomorphic type the polymorphic function is bound to, must be valid
for within the lambda as well.




defunctionalization example:

example with higher order function usage:

fn aux (f)
{
  f 1 + f 10
}

fn main (x, y, b)
{
  (aux (\z => x + z)) * (aux (\z => if b then y + z else y - z))
}

first-order defunctionalized version:

datatype Lam = LAM1 of Int
             | LAM2 of Int * Bool

fn aux-apply (LAM1 x, z)
{
  x + z
}

fn aux-apply (LAM2 (y, b) z)
{
  if b then y + z else y - z
}

fn aux (f)
{
  aux-apply f 1 + aux-apply f 10
}

fn main (x, y, b)
{
  aux LAM1 x * aux LAM2 (y, b)
// each higher-order application is instead an application plus
// some particular closure, this closure is then used by the
// dispatcher to call some particular instance of the closed
// over function and to pass information into the function.

// I think this could also be supported if we consider the
// lambda ast object as a record with two fields, the definition, and
// a reference to the closure (tuple-of-captured-free-variables).
// then, in the interpreter, the higher-order function can
// simply apply the lambda as it would any other procedure,
// with the closed-over-values being 'passed' as an implicit first argument,
// then when those names are referenced the lookup function would know to
// search the closure? that would make sense if it was a record instead of
// a tuple. then we can compare free variable names to the closures
// named fields. if this is actually the interpreter do we have the
// ability to run into this issue? (not finding a binding when executing the
// body of a lambda within the execution environment of the higher-order
// function? the name must have existed within the defining lexical
// occurrence, and that same environment is the one in which every
// higher-order function is evaluated.)
// in the compiled sense, the instructions constituting the definition
// will be pointed to by the first field, and the closure by the second field.
// the function call would be carried out by calling the address contained
// in the first field, passing the second field as an implicit first
// argument, a reference. then each instance of a free name could be
// referenced via the closure, (read data via address-to-closure-plus-offset)
// and setting up the rest of the arguments according
// to the formal argument list, in whatever way I decide to do that.
//  (probably the c calling convention tbh.)
}

------------------------------------------------

with closure as an argument

fn app (f, x)
{
 f x
}

fn main (x, y)
{
  (app (\z => x + z) 1);
  (app (\z => y * z) 2);
}

possible implementation:



fn app (f, x, closure)
{
  f closure x
}

fn main (x, y)
{
  app (\z => x + z) 1 (x := x);
  app (\z => y * z) 2 (y := y);
}

we can solve the downwards funarg problem fairly straightforwardly
by allocating the closure statically in the enclosing stack frame
and passing it inwards. however, this is the simplest case.
we will get to the harder version of this.


this means introducing a constructor for an object representing the
free variables present in the function at time of definition, and associating
those free variables with a closure-like object which injects the free bindings
into each call site.

notice how our own conception of what a polymorphic function even is,
aligns with this concept of defunctionalization.
instead of having a single polymorphic instance, we have a set of monomorphic
functions.
in a similar way, every time a higher order function is applied it can
be semantically supported by a call to a first order function with it's free
variables bound to whatever they had been bound to at the lexical definition
point of the closure (this is what it means to be statically lexically scoped.)
if we were to make a set of each of these functions we would have the set which
describes that particular closure.
if we were to make a set of every application of some particular polymorphic
function, we would arrive at Pinks definition of said polymorphic function.

so, how about we use that hinge to define a calculus?



each time the aux function is applied the compiler needs to keep track
of the free variables present within the application site.
in the first case, only the variable x appears
free in the higher order function passed to aux, therefore that particular
application site can be associated with a particular constructor for the auxilliary
function taking in that free variable as an argument, and preforming the
lambda body.
in the second site, both y and b appear free in the higher order function
passed to aux. therefore that call site needs to be associated with a separate
constructor which takes in a pair of arguments and passes those to the associated
apply function. then, in the body of the aux function itself, in order to
execute the application, we can preform type dispatch over the constructors
to select the correct first-order implementation.

if, instead of doing actual defunctionalization, we could implement
closures, we could instead of defining a constructor-per-application,
we could define an environment containing the bindings and associate
that environment with each application. then while executing the higher-order
procedure body we can lookup the free variables in this 'closure'
environment. we still need to implement a monomorphic version for
each type the higher order function is called with (unless it's monomorphic)
and we may need to dispatch based on type in the general use case. with
an optimization being calling the correctly typed instance directly.
(with each particular call site being associated with some particular
closure environment.) but, this saves us from constructing each application
site uniquely. (in the defunctionalized sense.) insted we can have one function
body which operates upon values of some type. and closes over values in it's
defining environment. each call site can receive a pointer to the environment
containing the bindings for the free variables occuring in the body of the lambda.

when we consider compiling such a closure,
we could pass the closure environment as a hidden
arument via a tuple, and then the sequence of instructions to access those
names are implemented with tuple lookup.
then this tuple can live in the stack or in the heap depending
upon the use case. we may still run into problems because the types contained
within the tuple change which series of instructions will validly retrieve
data from it. so this still seems to require a separate implementation
per tuple.

the question then becomes, what about a polymorphic function which closes over
some terms? well, since we define polymorphic instances as per-application, and
we define closure values as per-application, it seems to imply they are already
in alignment, so it may simply make sense to say that the closure
is associated with some application site, and then polymorphic procedures
which apply functions simply pass the closure they receive into the higher
order function and that function is able to utilize those bindings.
the function doing the application can be defined indempotent of which particular
function it is applying so long as the arguments align.
so do we have a type dispatcher per closure? or a closure dispatch on every
member of a polymorphic set? I think by normal coding styles no. these
would seem to me to be degenerate cases.

 this implies that the closure could be passed in as an extra parameter
to the polymorphic function and thusly the higher-order function.
the shape of the closure is dependent upon which particular
higher order function is being passed, meaning we can define the closure in the
environment that the higher order function is defined in then pass that closure
as an argument to the polymorphic function and then when the
polymorphic function attempts to execute it can simply pass whatever closure
argument we receive into the higher order function. meaning the stream of
instructions

-------------------------

we want any function which applies a higher-order function to be able to do it
without knowledge of which particular closure values or particular instance
of the higher-order function we are calling. (we want the two switch statements
to be able to live in separate memory locations. such that we can call one from
the other and visa-versa. rather than being forced into describing nested
switch statements. because that gets degenerately large fast.)

this allows the sequence of instructions which describe the function to be
identical no matter which particular instance of the higher-order
function is being called. this should isolate the dispatching logic to one
location, the dispatcher which exists per-function.
if we consider a lone formal function definition:

fn basic (x, y)
{
  x + y
}

we can imagine a sequence of instructions which implements this function for
every type that + can be validly applied to. (either we add two cells of memory
typed Int, or Real. or we call the function which is named + but matches
the actual types of x and y. for instance, a string concatenation procedure, that
allocates new memory of size length(x) + length(y)
and fills it with the string pointed to by x, and then y thusly returning
the concatenation of both strings.)

this monomorphic definition not only has no free variables,
and thusly no closure, but it's dispatch function, conceptually,
is over a set with a single member, the monomorphic definition.
meaning we can always factor out the call to any dispatch function as
an optimization.

so, any monomorphic function can be dispatched over by only comparing against
the formal argument list. and because this function contains zero free
variables. we can guarantee that any caller only ever has
to provide an argument list matching the formal parameters, and no closure.

Subsequently, since a polymorphic function is
represented as a set of it's valid monomorphic instances.
the physical parameter list of an actual callable implementation
is exactly those arguments which appear in it's formal argument list
with monomorphic types bound in place. we choose to delay the selection
of any particular polymorphic variable until such time as the programmer
request that we do so via an application of the polymorphic function.
since, by definition, the argument to a function is well-typed, we can
be assured that we will be trying to instantiate the polymorphic function
to some well-formed type, and since we require that the subsequent body
be type able, the resulting monomorphic instance of the polymorphic function
must itself be well-formed.
(this is proof of preservation and progress if i am not mistaken?)

when we see some call site of a polymorphic
function, while interpreting we can walk the set of formal argument lists and
then actually call the function body associated with that parameter list,
the closure then, is another data-structure entirely, which keeps track of
closed over values, thusly, the two features don't intersect logically.

the downwards funarg problem is the same for a polymorphic functions
as it is for monomorphic functions. the body of generated instances of
polymorphic functions are by definition identical, except for which types
they operate upon. interpreting can get by with evaluating a copy where
the type tags have been modified, but compilation seems to require that each
call site of some polymorphic function literally call a separate version
of the function from an application site

fn simple (x)
{
  y + x
}

in this case any caller has to provide the same closure value. whatever y is
bound too at the time of definition. in this case, any time we want to call
this function, it is always associated with the same y. only in the case
of an overloaded definition with a different set of free variables would we
need to provide a different closure.

fn aux (i, f)
{
  f i
}

fn main (i : Int, js : List Int)
{
  fn walk (nil)     => nil;
  fn walk (j :: js) => aux i (\x => x + j) :: walk js;

  walk js
}

in this case, seemingly we need to construct an arbitrary number of
possible implementations, one for each number appearing as 'j'.
which could be explosively huge. however to support the semantics
we only need to change which particular value
appears as bound in the environment each time we execute the body.
which is once per recursive call. meaning that if we allocate some
local space for the closure, we could simply assign the value in the closure to
the value of j (from the list) each time we recur.

or perhaps we would need to preform an allocation and a deallocation
each time to be fully generic, thusly constructing and destructing the proper
closures before each call.
perhaps in certain cases we can allocate the closure as a local variable
and pass the address to be written, and in other cases we are forced to allocate the
closure dynamically, however since we always *use* a ptr-to-the-data,
the implementation can be blind to where the closed over values are located.
 (we don't pass-by-value
in one case and by-reference in the other, we simply always pass by reference.)
then when we notice that some particular closure value is bound to a new value
of the same type each time (as is the case during looping and recursion.) we can
support the different binding during each call by assigning the cell representing
that closure value (whether local or dynamic) to the value of the cell containing
the new value. (in this case we would be taking about the cell which was pattern
matched into j from the current node of the list being processed, and the cell
of memory (which can probably be stored locally) representing the closure
value 'j'.) this requires the types be copy-constructable, in OO-speak.


essentially, the dispatcher for
a given function needs to dispatch on two aspects of the function. which
arguments, and which closed-over values are required. and both of these
facts can be deduced from the call expression.

(in the compiled case, we need to generate an executable monomorphic
version of the higher order function,
and then arrange to call a particular higher order
instance passing in the correct closure values.))


fn aux (f)
{
  f 1 + f 10
}

fn main (x, y, b)
{
  (aux (\z => x + z)) * (aux (\z => if b then y + z else y - z))
}

possible closure-like implementation:

fn aux (f, closure)
{
  f closure 1 + f closure 10
}

fn main (x, y, b)
{
// this isn't meant to be valid syntax,
// it is meant to convey which/when/where bindings are constructed
  aux (\z => x + z) (x := x) * aux (\z => if b then y + z else y - z) (y := y; b := b)
}

the last confounding case is the upwards-funarg problem, or
what the heck does it mean to return/store a function as a value?
well, our implementation could say "return a closure." which
lets a future caller of the returned value call that function
providing the correct closed over values. however, this implies the
existance of garbage collection? how does it? well lets think it through.
if we consider the returning case, lets say:

fn partial-add (x)
{
  \y => y + x
}


fn main ()
{
  x := partial-add(7)
}

it is my assumption that whenever the program
attempts to execute 'x' providing some value,
the storage representing 'x' in local memory will
contain a ptr to the implementation of x, and additionally the
closure values. then when we try to interpret 'x'
we will interpret it's implementation given that
we inject each binding in the closure into the execution
environment for the execution of the function.
in order to compile this program, we would need to
emit the instructions for addition to rely on the parameters
to find the value of y, and through the additional layer of
indirection to the closure, x.

the closure that x points to is usually allocated in the heap.
but what if we define the closure to store the closed over
values directly?

--------------------------------------------------------------------------------

given some polymorphic function application,
we simply do not have enough information
without instanciating a version of the function
with the type substituted in, which we can do here
iff the call tree's lhs node is the polymorphic
function directly, if the function is specified by
name, we would need to be able to evaluate the name
to get the body, to be able to then typecheck that.
so we do not have enough information in the general
case to be able to typecheck a polymorphic procedure
application. however, if we have a valid monomorphic member
in the procedure-set currently being typechecked,
we then do actually have enough information
to for real typecheck the call expression.
so when we typecheck a call, we have to search the
ProcSet for a potential matching argument type.
if we find a matching argument that is actually exactly
enough information to make the typing judgement then
and there, if we do not find any overload/monomorph,
but the function itself is polymorphic then we have the
freedom to create an instance of the function with the
given type, and check to see if we can type the function
given that type. if we can type the resulting function
we store it into the ProcSet and return the resulting
type. if we cannot type the resulting procedure, that
is enough information to report a type error.

--------------------------------------------------------------------------------
#! language-philosophy

basis/thesis of something being judged true or false
basis: what makes it true?
thesis: what becomes true if we can assume that the something is true?

then we need some way of constructing arbitrary sequences of valid terms,
  (the construction of which must give more components in
   the construction of still further terms.)
then we need some way of judging the basis/thesis of these sequences
such that we can validly construct a proof from some starting point
to a fixed goal "something being judged true or false."

-------------------------------------------------------------------------------
#! working through parsing
a term is either:
a variable
a literal
an application
an affix expression
where
a literal can be a function literal,
  or the literal value nil. (this is also
  where we find numeric literals, character and
  string literals, and so on.)
an application is any valid variable/literal
  next to another valid variable/literal
and an expression is composed of and valid
variable/literal, followed by a known binop,
followed by another valid variable/literal.
we can distinguish between an application
and a binop only after parsing the first valid
term. however, since application is always higher
precedence than operation we choose to always parse terms
into an application sequence starting from when parse_primary
is called to the point in the tokens in which we recognize
a binop, or an end-of-term token, such as RPAREN,
or REQARROW, or END. then, when that call to parse_primary
returns it can be collected into a call expression by the
caller. which is only ever because parse_primary itself called
parse_primary, specifically because it predicted another
primary term after it parsed a primary term. this recursion
needs to bottom out when we see a binop or another end-of-term token

if primary terms subsume recognizing function application,
recognizing literals, and recognizing variables.
then we can describe binary operations
in terms of a primary term followed by a binop,
followed by another primary term.
this also allows  call expressions to be built
up recursively by way of predict_primary vs. predict_end.
if we predict another primary term then we construct a
call node from the previously parsed term, and the node
created when we parse the predicted primary expression.
if we predict the end of the expression then the result
term is what was already parsed and we can simply return.
whatever 'end' token we saw will be handled by some caller.
as an example:
if we imagine parsing some call expression of length (n)
t0 t1 t2 ... tn
t0 is parsed by parse_primary, then the function
predicts another primary so we prepare to construct the
first call node by calling parse_primary again to construct
the rhs of the node. then we parse t1, and again,
predict another primary term, so we prepare to construct
the second call node by calling parse_primary again,
and so on until we parse tn, and predict the end of the expression.
then we place tn-1 and tn into the lhs and rhs of the bottom-most
call node and return the call node to the node above,
and then that call node has it's rhs ready, and so on until we build
up the entire tree.

then, each of the literals can be parsed by their own function
and it is simply a matter of directing the creation of the correct
entity node, and connecting these entities together by means of
the connective tissue nodes, operations and applications.

--------------------------------------------------------------------------------

the general form of a binary operators
expression tree, as if it were
procedure application.
       call
   call    rhs
op    lhs

then, evaluation of a binary operator can proceed thusly:
  - search environment for the operator (if it isn't a primitive op)
    and then check that the type of the lhs and rhs are correct.
    do we need to check the types tho? didn't the typechecker do that?
  - mechanically transform each binop into a call tree
    as above and return the result of evaluating that
    tree.
  - this transformation will bottom-out at the set of
    primitve operations understood by the language.
    adding two numbers, concatenating two strings, etc.
    (at least in the interpretation sense.
    compiling a binary operation will presumably
    produce the series of instructions needed to
    perform the operation, upon the literal values or
    memory locations.)

one can notice that there is an assumed step of computation
that may be useful. (if one notices that it takes two applications
to execute the binary operation.)
one can imagine that we half apply some
binary operation, such that we now only need to supply
a single value to recieve a result.
like (3+), (42-) (56*), (/4), (4/), etc...
this could be naturally supported by the above interpretation
if we were careful in adding support for parsing and
saving the notion of half a binary operation.
these would presumably be parsed as unops in the pre or postfix
positions.
(binops are always postfix. binops could presumably also be
 a pair of symbols, then we could acheive something like
  c's [] array derefrence operator.
 and we can define it for arrays (taking a number),
 tuples (taking a number), and a hash-table (taking a string))
I am unsure if this is a good feature or not for pink, but it is a feature
that is coherent semantically and syntactically.

overloading can proceed identically to overloading
formal function definitions, all that is really required
is modifying the lexer/parser/and the gang to accept strings
of special characters (&*^%$#@!~`'><=+-) as operator identifiers, and thusly
defining new binops and unops.

I also really love the idea of directly supporting Unicode
and having special forms tied to neat Unicode chars, like having
the literal greek lambda (λ) symbol be the anonymous procedure predicate
for the parser. being able to call a summing function uppercase Sigma (Σ)
This conflicts with most peoples keyboards however. (but again, this is
a play language.)

--------------------------------------------------------------------------------
 (think through what happens when we call the function
  'lookup' on a free variable which occurs in the value
  being substituted into the body of a lambda, after
  execution of the substitution whose name matches the
  lambdas binding name;
  when lookup tries to resolve the name, it will encounter
  the definition of the argument binding before
  it will encounter the binding that existed at the
  time of {value}'s creation. hence, the unintentional
  binding.)

  the generally accepted solutions to this problem are
  -renaming the argument of the lambda before substitution.
     such that no binding will occur. (what we go with)
  -making it so the evaluation of terms doesn't depend
   on names. this can be achieved in two ways
     -De Bruijn notation (which changes the names to numbers
       and maintains the separation point which denotes the current
       outer scope, below which no renaming need occur, (which is a
       consequence of the reversed numbering (zero is the most recent binding)
       , making the largest known value the oldest created binding.))
     -Combinator Calculus. which replaces names with some number of
       basic primitive functions. (there are a lot of different
       iterations of this idea, SKI, BCSKI, iota, etc)

 because of the simplicity of implementation
 we will choose to rename the binding of
 the lamdba abstraction throughout it's body before
 we substitute for the value.

 this has two downsides pointed out by some literature
 -it can be hard to reason about correctness formally
 -it relies on string manipulation, which is less efficient
   than the integer manipulation that De Bruijn notation
   relies upon.

 we don't need to reason formally about the correctness
 of Pink, if we can test it's correctness, and play with the
 system, in fact mostly just to play with the system.

 string manipulation is something that I am willing to
 spend cycles on. especially early on in the languages lifetime.
 especially when we aren't building large programs,

 I can see an argument for conversion to a DeBruijn manipulation
 of terms for a more final form of the interpreter.
 along with linearizing the tree traversal algorithm,
 and separating the walking from the actions. as that would
 have an impact on every module of the code that can be written
 as an operation upon the tree.
 Which is a large portion of this program.


 how do we know if the name bound to the lambda occurs free
 in {value}? well,
 a possible solution would be to gather the free
 variables present in (value) into a list and search that list
 for the argument name. this is in fact the solution that imo
 most straghtforwardly flows from the formal definition of substitution
 and renaming.
 however, this would require at least
 as much work as searching the tree directly
 to build the list of free variables, plus
 the work required to then search the list.
 (not to mention all of the allocation and deallocation
 of the list itself.) (there is no such thing as a zero
 cost abstraction. though i can believe a low-cost abstraction.
 think arrays vs linked-lists when accounting for an actual physical
 cacheing architecture.)
 it is more efficient to directly search the subtree
 for free variables of the conficting name. but this
 becomes another place where the algorithm is tied intimately
 to the structure of the Ast.

--------------------------------------------------------------------------------

okay, how do we add numbers to this system?
because we also want to add infix expressions
and the straightforward grammar (at least imo)

term:
    id
  | int
  | nil
  | nil_type
  | int_type
  | lambda
  | call
  | binop
  | unop
  | '(' term ')'

produces over ten reduce/reduce errors, which are nasty,
which makes me think that we have two choices,
add more symbols in a structured way such that
we can remove the reduce/reduce errors.
which is a lot of work that i don't understand that well.
because it's working with bison. OR, i can rewrite the parser
by hand, get back to current functionality, and then
extend that parser (which would be a packrat parser i think.
taking a few pages from the early-version hand rolled parser.)


  the strategy when writing a parser is to separate
  the values from the connective tissue, let the
  functions which parse values do just and only that,
  and let the functions which parse the connective
  tissue do just and only that, then each location becomes
  the obvious semantic place to construct the abstract syntax
  nodes that represent the respective value or connection,
  which when combined with the fact that we aligned
  the Ast constructors with the structure of the literals
  and connective tissue they represent, means we can even
  express the mutually recursive definition relatively naturally.
  all supported by the abstraction of a typed ptr and record + union of types.


  which goes to show just how powerful the simple constructs are,
  and how composable they are. the more complexity a component
  presents the less composable it is. which to some extent says
  that the larger a component is, the less composable it is.
  except size doesn't refer to physical space here, but complexity and mental
  space. a large array is no more complex than a small array,
  but a red-black tree is always more complex than and array, and hence,
  more of a memory and processor footprint, than the array.
  both of these abstractions are less complex than a SQL interpreter.
  and use less overhead in memory and processing.
  (notice how this again lines up with state and behavior.)
  while all three abstractions support essentially the same abstract action,
  the storage and retrieval of data, what each brings to the table is
  a set of constraints-of-existance, and constraints-of-use.
  (again notice, state and behavior)
  the constraints-of-existance are those aspects of the abstraction comprising
  it's physical footprint, how large in space it is, and what types it works with.
  the constraints-of-use are those aspects of the abstraction comprising
  it's mental footprint, what it does, what it can be used to do, what constraints
  does it impose upon input/output? what constraints does it impose that cannot be
  expressed in the literal text of the program? what constraints can be?

  each abstraction has it's own set of constraints, which must be considered
  by itself when working on that abstraction, and must be considered in tandem
  when working with that abstraction and another abstraction. the more
  abstractions which are interoperating the more of an overhead working
  with that interoperation is. if we observe that complexity arises in some
  location, we as programmers can work to reduce that complexity. there are
  many ways we can approach the problem of "removing complexity", one of the
  simplest is the straight removal of components, however one of the constraints
  we generally impose upon abstractions is that they provide the same behavior
  given the same input. and removing components can make it difficult or impossible
  to maintain the same semantics. so, instead of
  removing components wholesale, we can observe what behavior, if any, the
  components provide that can be provided by some unifying abstraction.
  this reduces the complexity of the portions of each component which
  had to reimplement portions of the unifying-abstraction, and instead each
  component can use the abstraction.
  if we instead observe that two or more
  components behavior can be subsumed by another abstraction, we can replace
  the components by some replacement abstraction which maintains the same semantics,
  this removes complexity in the sense that the complexity of the replacement
  abstraction is less overall than the complexity of the interoperation
  of the replaced components. (we can trivially observe that we don't
  benefit if the replacement abstraction is more complex than the interoperation
  of components.)


  notice two things, alignment leads to clearer design,
    spending time aligning components is what one can
    consider the task normally named "papering-over"
    or "fenagling" and the like. when and where two components
    logic become aligned, is when and where we can encode our logic.
    in some sense, this is the only process that happens in programming.

    we simply align between four points,
      state, behavior, goals, and constraints.
      what we have (in the previously written behavior and state sense.),
      what we can do (in the beta-reducible sense),
      what we want to do (in the what is the purpose of the project sense),
      what we can never do (in the beta-reducible sense, and the project purpose,
                           ethics, and consumer-market sense).

    this leads into the second thing to notice, the alignment
    of the composition of data with the composition of the
    algorithm. this becomes the anchor point for our logic just
    like alignment between abstract components, except.
    the alignment between data and the algorithms is
    the alignment of the program as a whole. this flows
    directly from the observation that programs are always
    fundamentally composed of two things, state and behavior.
    if we consider the alignment of the programs algorithms
    with it's data we will simply consider the program.



 gdb -tui <program-name>

 opens gdb with a scrollable view of your program.


  one of the problems that is starting to become clear
  is the tension between what the typechecker calls
  a valid program, and the actual semantics which
  arise from the body of functions. the raison d'etre
  of typechecking is to ensure that a typeable program
  is a program that will not generate runtime errors.
  {source: https://mitpress.mit.edu/books/types-and-programming-languages }
  however, this is not possible through tree analysis
  of the program alone, as the sources of error are too
  varied and unknowable for static analysis to cope with.
  however, this does not disqualify the type system from
  existence, it simply points out that the class of
  errors which are knowable through static analysis is
  some subset of the full set of possible errors.
  the really nice thing about static analysis however is
  the properties that it shares with mathematics in general,
  namely, it is deterministic. (depending of course
  on the specific typesystem, this is words about some idea of a
  typesystem, not specific typesystems, or about judgements which
  are undecidable.)
  in layman's terms, it always finds the errors it is looking for
  if they exist in the source text; and since the typesystem runs each
  time we attempt to compile or execute the program, so it is always
  making judgements about what code exists now. it's judgements cannot
  become outdated in the sense that a programs comments can become
  outdated. for the programmer to change the typesystem's judgements
  they must necessarily change the source text itself.

  these two ideas of the program's semantics can become
  unaligned in specific cases.
  For instance consider the UNIX system call: exit,
  which in the language of Pink
  has the type Int -> Nil, that is it's a function
  that looks like it takes an Int value and returns
  nothing. however the actual result of calling this
  function is that the caller is taken off the
  scheduler's list and stops executing.
  now, this may seem like a minor semantic difference,
  especially since you as a programmer have to type
  exit(some-num); and are presumably writing a path
  of execution that intentionally calls exit.
  however, to the compiler exit is just another function,
  that can be called, so if a programmer were to make the
  error of calling exit, and then writing code after that
  call expecting the program to evaluate that semantics,
  they would be dissappointed to find out that code
  existing after the call to exit will never be able to
  execute, it is in effect unreachable, and dead. now, in the
  knowable error case of the programmer writing code
  after the execution of a return statement, the compiler
  can issue a warning, it can delete or never compile
  any code that appears dead in the source text in this
  manner, and in general the compiler writer can choose
  to preform actions when the case arises. however in the
  case of an operating system abstraction such as the call
  to exit the compiler cannot know that a call to that
  system function will result in the program stopping
  execution, and therefore it cannot issue a warning,
  nor can it remove the dead code from the program source.
  in effect the error cases that can arise from using
  the operating systems abstractions is by definition
  larger than the set of errors that can arise from
  using the language abstractions, just when considering
  the two from a theoretical perspective.
  however the larger issue in the design of the language,
  and really in the design of any language is that
  the semantics of the program source text is only ever
  able to be partially checked for correctness.
  the gap that exists between what the semantic analysis
  can perceive and manipulate and what the programmer can
  perceive and manipulate is large. and if we want to
  automate checking the correctness of the programs semantics.
  we are attempting to bridge that gap, this can be begun by
  writing tests. but it will soon become apparent that
  wether or not your question can be asked systematically has more to
  do with what question you are attempting to answer than
  what problems you are trying to solve.
  if we recall our earlier example, the difference between the
  implications the type gives to the meaning of a function
  and the meaning of the actual function may or may not be aligned.
  and one fundamental problem is that
  the typechecker can only truly decide based on the exact
  implications that the type information brings (which is
  to say the noticably smaller of the two categories.)
  consider again the Linux syscall exit, say as language designers
  we decide to give it special meaning, and makes it so we can
  issue a warning/make judgements about it's actual meaning.
  well, then why stop at just one syscall? what is the argument
  against just adding special consideration for operating system
  abstractions into the understood semantics of the language?
  well, the strongest argument for me is the dependency it
  introduces on the core language, firstly it says the
  core language includes some notion of the operating system,
  (which is another program authored by other people, so keeping
  pace will take extra work) and secondly it asks another big question,
  why not the other operating systems too? these both add a lot of weight
  to the project that I as a single engineer cannot keep pace with.
  in the end, a library is a better home for these things
  because they are not fundamental to the core of the language.
  this alleviates the core from having to consider as much material,
  which helps the design by not adding as much meaning to enforce/know.
  adding special meaning to expressions to subtly alter the
  underlying semantics is an active area of interest to this language
  because it addresses a few fundamental problems, two of which are how do
  we address what c calls volatile semantics, and as a mechanism
  for maybe saying to the compiler that exit() will cease the operation of
  this program, etc.

  however what types really bring to the table is that
  reasoning can be encoded into them. types in
  particular are the axis on which modularity swings.
  where functions can abstract over reasoning,
  types can encode reasoning, allowing functions to
  abstract over still further reasoning. what static semantics
  enforce about usage of type ensures that usage of
  type is correct (in-so-far-as the typechecker can actually check,
  as it turns out a lot of interesting and potentially useful
  properties cannot be decided through static analysis.)
  which means that orthoginal to the meaning we as programmers
  have added to some particular semantics, the compiler can
  also interpret those semantics to evaluate them or to
  produce a program with those semantics in some other language.

--------------------------------------------------------------------------------

  my previous attempt at the precedence table
  obviously we want to maintain the same precedence
  relations between the common math symbols. and also
  understanding that for many, the c precedence table
  is de-facto standard for programming languages.

  so, starting from the perspective of emulating mathematics
  we want to preform basic actions on numbers/entities.
  3 + 4 * 5 HAS TO parse to (* 5 (+ 3 4))
  when a programmer wants to preform bitwise operations
  on numbers, they probably want the bitwise operations to
  operate on numbers which have already been manipulated
  to some final value.
  x || y * z,
  likewise when we go up a step to the logical connectives,
  we want to test for truth and falsehood upon values which
  have been fully operated upon. a + b > c * d.

  the same argument is made when we take another step up to
  equality comparison.
  say to the case of
  a + b > c * d == e - f < g \ h

  we want to test for equality between the largest lhs and right we can
  group together. because we are assuming the programmer wants to compare
  between fully evaluated terms, which implies gathering as many operations
  into the evaluation tree before we insert the comparison operation.

  and, the same argument extends to the programming language specific operators
  ',', ';', ':=', '[', ']', '(', ')', '{', '}'
  and the type connectives '->', '+', '|', '&', '!'

  why do I invert the logical symbols and the bitwise symbols?
  well, for logical consistency, and the fact that logical connectives
  are more common than bitwise operations, by a wide-margin.
  (and now, LSHIFT <<, and RSHIFT >>, align with the rest of the
   bitwise operators OR ||, and &&, and xor ^^, in being two symbol operators.
  )
  when we consider equals and not equals, =, ~= resp. one can probably intuit
  the meaning of the compound symbol ~= just from knowing that = means equal-to
  and ~ means logical-negation. this also aligns with ~ being the logical not.
  instead of ! as in c. why is that? well, the operator *, is used to represent
  type kinds in the theory, and it would be nice to align the language to some
  theory symbolically. since we are deciding to reapropriate * for types, then
  it could create confusion to also use it as the indirection unop. so we will
  pay some homage to ML by taking ! to be the indirection operator. which takes
  ! away from the logical commectives, because again too much overloading
  increases the cognitive complexity of the kernel, and so we must select
  a new symbol for logical-negation.
  hence, ~ for logical-negation, and ~~ for bitwise negation. notice how
  this aligns with every bitwise operator, being composed of a repetition
  of some other operator. when a programmer sees a || instead of a | it should
  always be able to be read as a bitwise operation. this at least holds for the
  kernel, obviously if we give programmers the tools to both overload existing
  operators, and define new operators, they can define new operators which
  negate the truth of the above statement quite easily. but that is separate
  from the logical consistency of the kernel.

  (normally in ML ~ is the unop minus to the binop minus -, we just use the
   fact that unary minus always appears in prefix position and disambiguate
   by the position instead of symbol the operation to be carried out. meaning
   both forms of minus are symbolically stated by the - symbol, this is in
   some sense of the word, overloading the symbol with two meanings, however
   since the two meanings are entirely disambiguated by the grammar there is no
   need to consider any special logic to support the two definitions, we can
   )


    ptable[T_COMMA] = 1;
    ptable[T_EQ] = 2;

    ptable[T_EQUALS] = 3;
    ptable[T_NOT_EQUALS] = 3;

    ptable[T_LESS] = 4;
    ptable[T_GREATER] = 4;
    ptable[T_LESS_EQUALS] = 4;
    ptable[T_GREATER_EQUALS] = 4;

    ptable[T_OR] = 5;
    ptable[T_XOR] = 6;
    ptable[T_AND] = 7;

    ptable[T_BIT_OR] = 8;
    ptable[T_BIT_XOR] = 9;
    ptable[T_BIT_AND] = 10;

    ptable[T_BIT_LSHIFT] = 11;
    ptable[T_BIT_RSHIFT] = 11;

    ptable[T_ADD] = 12;
    ptable[T_SUB] = 12;

    ptable[T_MULT] = 13;
    ptable[T_DIV] = 13;
    ptable[T_MOD] = 13;

--------------------------------------------------------------------------------

each procedure is represented by a defining instance,
   and zero or more alternate instances.
   every implicit instance is created when the procedure is polymorphic
   and the user executes the procedure while providing an explicit type.
   each explicit occurance is denoted by a definition of the same name.
   notice how the explicit binding mechanism forbids the creation of
   a lambda literal with the same name as another lambda literal.
   this implies that each lambda literal must be represented by a unique
   overload set. the only way the programmer can syntactically request
   an expansion of an anonymous procedure set is by implicit creation,
   that is, only polymorphic lambda literals will ever be represented by
   more than one sequence of execution. and that is if the user writes
   a sequence of execution which calls the same polymorphic lambda object
   passing in different types.

   what about closures?
   z := (\x => \y => x + y) 3

   z = \y => 3 + y

   (notice, \x => \y => x + y could have members of type
    Int, Real, and String/Text. but the returned function
    \y => 3 + y, y only works on values of type Int.
    the fact that the arguments type is polymorphic is
    enough to say, we could theoretically imagine a valid
    type for this expression, so trust that when a value is
    provided it will typecheck. and that is enough to build
    up types, as long as we accept that polymorphic types
    can be given any type as an argument, and we only accept
    or reject the resulting definition based on wether or not
    the new definition still typechecks. if we imagine the
    polymorphic type being built up recursively, then it must
    be instanciated by an acceptable type each time.

  )


   the function set that represents the returned
   procedure literal is unique to that procedure literal,
   that is, the set that is returned
   is responsible for storing the closed over values for later
   execution.
   any named intermediate step can be associated
   by some set of functions in which each member can be associated
   with it's own sequence of instructions sitting in memory somewhere.
   any closed over values can be stored in the same way any value-explicit
   local name would be stored.
--------------------------------------------------------------------------------

question:
  what tasks in particular force the c language programmer to
  drop to assembly, and why can we not envision sensible
  abstractions which encapsulate these tasks in a higher level
  language?


one task is the context switch.
  where the operating system takes one task off of the running
  state and stores it in memory, then loads a new task into
  the running state. doing this requires directly talking about
  the registers in use by the current program, and the registers
  in use by the new program. (as well as a myriad of other OS
  subtleties I am sure.)

  why does c fail?
  the programmer has no way of
  directly referencing the data in any of the working
  set of registers.
  essentially we can't say "save register rax into memory"
  in the language of c.
  why does c not provide some sort of a built-in?
  well, the notion of a hardware register is
  not directly knowable at the level of abstraction
  in which a programming language operates.
  the very notion breaks from the idea of operating
  a level higher up from the hardware itself.
  we can make sense of the statement rax = some-word-sized-value;
  from a language implementation
  perspective, it is difficult though not
  impossible to envision what changes to the compiler
  is required to allow the programmer to store
  and directly access the active register set.

  specific compilers have specific ways of inlining
  assembly, but that means referencing the mete-material
  of your compiler, and this binds your project even tighter
  to which specific compiler you are using which could
  have consequences. (and you have already decided to write
  assembly, so you, by definition, throw portability
  out of the window for that particular component.)

  you can always write a separate
  assembly source file and call your assembly like a c-function,
  (using your favorite assembler)
  though this requires knowing the c-abi of your
  particular operating system and it assumes that
  your language has a c foreign function interface,
  which admittedly plenty of languages do.
  (c's abi is very straightforward)
  additionally, assembling a separate assembly
  file complicates your build process somewhat.

  what really throws a wrench in the works
  however is our goal of portability. which
  specific registers you have access to is a matter
  of which exact specific CPU you have, and is usually
  only knowable by referencing the exact relevant documentation.

  so, these two factors (portability negation, having to
  descend a level of abstraction to get things done), to me
  point to the solution living outside of the kernel of the
  language. if we can construct the relevant semantics
  to speak assembly, or somehow give direct handles which
  can be accessed by the understood abstractions, but do it
  by composing together the more base abstractions that we
  have available in the language already. like, maybe
  we define what a base CPU type would need to provide
  through an abstract type a'la ML, and specify what the
  writer of a conforming CPU structure should export
  like, general purpose registers, floating point registers,
  and status registers, then a conforming implementation of
  a specific CPU structure could conform to what is specified,
  but also export more signatures which could represent the
  specialty features of the CPU or specialty hardware components.
  then, programmers could utilize that abstraction to write low
  level code, that interacts directly with the hardware, while
  saying it in the syntax of the language. and, if you want to
  write code that preforms a task switch you can do so against
  the abstraction, which hopefully can compile down to some minimal
  assembly.


another task is driver development
  when talking directly to hardware, most of what is
  being done is managing state. some but not all hardware
  is built based on a standard (or de-facto-standard) abstraction,
  which implies that there is some abstract data type which
  could encapsulate the state management and provide some
  nice interface for the language. in example, one could
  imagine a UART device interface that provides a memcpy
  style interface where the systems programmer just has to
  specify which array of bytes they want written to the device
  and a single call handles that for them. so, this immediately
  runs into complications when considering implementation of a memcpy style
  interface with a UART device. it would seem to imply that the programmers
  code stops running until the UART device was done transmitting.
  a trait that we probably do not want to have, given that UART
  data transmission is orders of magnitude slower than the CPU.
  in order to facilitate some sort of time disconnect
  there are a few different abstractions that one can choose from,
  you could describe it with coroutines, async/await,
  threads, or you could leverage the interrupt mechanisms of the
  CPU, each choice has a distinct effect on the shape of user code.
  and on the semantics of user code in some cases.
  in my mind, a good systems language would give the tools in such
  a way that programmers can write each effectively, and a clever
  api programmer could insulate user code from the difficult choices
  allowing learning programmers to utilize the hardware they have
  in a sensible, safe, and (hopefully) as fast as the hand-rolled
  assembly could hope to be.

  parts of this problem that add layers of complication:
    there are lots of different hardware protocols!
        which ones do we support?

    those de-facto-standards make for inconsistent hardware
      designs, where some hardware claiming to implement the
      same standard transmission protocol like SPI, could
      implement the standard in subtly different ways,
      such as different STOP bit patterns, different START
      bit patterns, parts of the standard are unimplemented, etc.

        how the heck could any single algorithm be written to account
        for all those subtleties?
        essentially, we can't have
        "the SPI algorithm"
        we have to have
        "the <device-specific> SPI algorithm"

        but could we imagine
        "the conforming SPI algorithm functor"?
        and then specializing it per-device?
        because if we can, that can help to insulate
        programmers code from driver code.

--------------------------------------------------------------------------------

notes about parsing with bison:

the type here (%nterm) needs to be able to directly
represent each node in the grammar.
of which there are 5.

in the trivial calculator, we can get by with
each term having the same type. namely int.

here we need to express the abstract syntax tree
in terms of a c-style union. which is an untagged
union. since we are compiling in c11 mode I think,
we can specify unnammed unions in the ast, so we can
just say, AstTypeName.nil instead of refrencing it
through AstTypeName.union.nil
making our declarations here look more like we are using
the regular bison union, but each AstNode also tracks its
kind and type making the rest of the compilers job more
straightforward.
(spoiler alert, we can't)

to paraphrase the bison documentation

%nterm <typename> nonterminal

this statement declares the nonterminal to be represented
by the name 'typename' within the union type 'api.value.type'.
additionally any number of nonterminals can be declared here
and all will have the specified type

my question:
  what is the type bison selects for %token directives that
  are used trivially within the grammar? especially in the
  circumstance in which I have specified my own custom type
  in api.value.type

the best response I've found from the documentation:
{from: https://www.gnu.org/software/bison/manual/html_node/Mfcalc-Declarations.html}
  "Since values can now have various types, it is necessary to
   associate a type with each grammar symbol whose semantic value is used."
   "The Bison construct %nterm is used for declaring
   nonterminal symbols, just as %token is used for declaring
   token types. Previously we did not use %nterm before because
   nonterminal symbols are normally declared implicitly by the
   rules that define them. ~~~But exp must be declared explicitly
   so we can specify its value type~~~"

My assumed answer:
  don't worry about it unless you are relying on the terminal/nonterminal
  symbol having some particular type, in which case specify
  that type with a %nterm, %token, or %type directive.

  if you attempt to access the value of a non-terminal or token that
  does not have a type associated with it, bison will reject that
  grammar.

this raises an additional question,
  if 'typename' is the expected name of the union
  field associated with the terminal/nonterminal symbol,
  then what about places where we parse some sub-field
  of an entity?
  such as, i am reading the name of the argument, i would
  like that stored as a trivial char* until i can record it
  into the full lambda ast node, after consuming that input.

  the way the documentation is worded makes me assume that
  even if i add some new terminal symbol it will be represented
  by a full Ast node by bison? or maybe they secretly aren't
  but only nonterminal lhs values are constructed as Ast nodes.

  this is why the %token <typename> TOK
  directive exists.

the final verdict:
  all of these issues are solved by using pointers to a union value
  and only making bison differentiate between simple char*'s and
  Ast* nodes.
  when we extend the data we need to track to strings and integers
  and floats and such, we must extend the grammar and probably
  the underlying data-representation to account for the new data.
  we will distinguish between Ast* nodes, char*'s, Ints, and Floats,
  but again, -we- should manage that, and constrain the LALR parser
  to just construct the AST.


------------------------------------------------------------------------------

term:
    id
  | \ id : type => term
  | term term


  consider some primitive type *

  where shall it live in memory?
  well, given that the we mean for the
  full set of knowable types to be static
  before the program begins execution,
  and given that we require each name
  which appears in the source text of
  the program have a known type before
  the program begins execution.

  we can allow types to be defined statically
  by the programmer, but each type must have
  a static definition present in the source text.

  what distinguishes the type *
  from our other type  * -> * ?

  well, the size of each instance of a specific *
  is bounded before the program runs.
  Int, Char, Real, Bool, Nil.
  each has a statically known and unchanging set of
  values any entity with said type can be assigned.
  any entity which has this type can be allocated exactly
  as any other entity of that type would be. meaning
  the type is in some ways a description of the
  entities representation in the hardware.
  we have instructions which operate on integers,
  we can read/write integers from/to memory,
  and that's really all we can ever do with integers.

  if we have an expression which acts upon integers
  say 3 + 4
  that expression has static size.
  if we consider an expression acting on entites,
  if the entities type and value and the operation are known
  in the source text, then the language can compute the
  expression directly during compilation or interpretation.
  if x := 3 + 4
  then we can assign 7 to x instead of preforming the
  computation at runtime.

  if x:Int, y:Int
  then x + y also has static size, but the value of the
  expression is not known until the value of x and y is known.
  so, we can know that it is safe to store the result of
  computing x + y into z by means of the following expression
  z := x + y. if we were to simply enter this expression
  into an interpreter, then it should rightly complain that
  x and y do not hold any values, so we cannot know what to
  store into z.

  ( aside:
    so, we want to initially circumnavigate this issue a bit
    by allowing out of order usage/declarations, which allow
    programmers to enter recursive/mutually-recursive
    functions/types, which are useful. so maybe instead of
    immediately complaining, the interpreter asks for more
    user input in the hopes that a definition for x
    or y would be entered by the user, maybe this could
    be the case for other constructs in the lang?
    and maybe the compiler would eat input until EOF looking for
    a decl after use.
    )

    if you want to parametrize the expression, and
    preform the operation potentially on many entities
    of said type, then you can define a function.
    this is the purpose of the other type in the language
    * -> *
    but how big are functions, and where are they allocated?
    especially if they are first class! what in the heck can
    it mean to pass instructions around?
    well, maybe we don't pass instructions around, but we
    reallocate the instructions in places where it becomes
    unavoidable to do so. in simple cases, passing lambda's
    into other functions can almost assuredly be semantically
    represented via function pointers. with the lambda itself
    being allocated locally in the definition of the outer
    function, passing a function back can be done via a function
    pointer as well, as long as there are no closed over values
    in the passed back function, (in a simple case, something like
      \x:Int => \(y:Int, z:Int) => x * (y + z);













































------------------------------------------------------------------------------
