

to gain more understanding about any system,
one can strive to understand the sources of tension within it. 
the conflicting points of view.

(thesis + antithesis) -> synthesis

what about points of view that are not entirely opposite or
entirely cohesive, but some mixture.
well, how about

(thesis + polythesis + polythesis + ... + polythesis) -> synthesis

and/or

(thesis + polythesis + polythesis + ... + polythesis) -> (polysynthesis, polysithesis, ..., polysynthesis)



what are the points of tension on the design of the langauge?

so, in order to talk about that we must fist define our context:

any language exists in the greater world.

the language also exists in some local environment, running on some physical hardware.

the language has its own existance.

the language defines the existance of other programs. (even other languages)

language concerns are generally all important, but will have a different
importance order depending on your perspective and external constraints.

language perspectives include:
what is the user concerned about vs
what is the language implementer worried about vs
what is the library writer woprried about vs
what is the OS writer worried about vs 
...

the tension in the language is defined by the conflicting
goals of the language. and as hinted at above, sometimes design goals
arent so much in direct competition with one another, but they do still
have influence.

language goals include:

- Expressivity + Communication
	the language should enable programmers solve their problems, rather
	than solve the riddle of how to express what they want to say in the
	language. 
	
	"stop telling me what you are going to say, and just say it."

	Programmers fluent in the language should be able to easily read what
	one another are saying and doing in their code. 
	common abstractions should have a common form
	common tasks should have a common form
	it should be easy to say what is easy to do.
	it would be really nice if it was easy to say what is hard to do.

	the language should be designed to communicate effectively what
	the computer is doing to other human beings. 

- Orthoginality
	Language features should interact in an understandable, definite way, which
	allows them to be composed together indiscriminately. or at least in a way that 
	makes some sense and is communicated to the programmer. one should never have to maintian
	a laundry list of edge cases in their head while they program. usage of abstraction
	is the problem, composition of abstraction is what the languages job is.
	the programs that are being expressed in the langauge are of the real
	importance to the programmer, and the usage of the language should reflect this.
	of course, with a systems programming language some concessions will have to 
	be made to understandability in the name of performance.
	but again, it would be nice to be able to hide those from the user of the language in 
	a user friendly abstraction; like replacing the GOTO with while loops, if-else if-else
	chains, and parametrized functions.
	but the language should be no harder to learn than C.
	
	(...or at least the list of edge cases should be as small as possible,
	 and only occur when a sensible default makes no sense.)

- Maintainability + Testing + Documentation
	Code that is written today, may be talking to code that is written 20
	years from now. This is not something that can be ignored. How does this
	affect the other dimensions, and how does the language assist programmers
	in this dimension.

	testing is a non-trivial aspect of development, that also has a uniform
	shape. How does this language assist programmers in testing their own code?
	in testing unknown code? the language implementation itself will be tested,
	so there are obvious advantages to having some form of default test suite,
	and good capabilities built into the language. (first class functions seem
	like the best abstraction to write a test suite on for me.)

	Documentation is one of the most important tasks in development, and is also
	often one of the most overlooked in terms of quality, and effort. Documentation
	has a bad habit of being continuously out of date. how does our language help
	programmers write and maintain better documentation?

	
- Performance
	writing code that utilizes its resources effectively is difficult. writing
	interoperating abstractions that can utilize shared resources is difficult.
	performance modeling should be easy to do, and require minimal cognitive
	overhead. the shape of performance modeling is uniform in the same way testing is
	so the language should have nicities.

- Portability + Hardware Interaction + rehostability
	A program written without using language constructs that tie it directly
	to the hardware, a.k.a. in a portable way,
	should be able to be compiled and executed on any platform the back end of the compiler
	supports.

	But what do we afford the programs which do want to tie themselves heavily
	to the hardware? what about the programmer who has resource constraints,
	or other esoteric constriants?
	if your particular project is running on an 8-bit micro processor, 
	your view is very different to that of a processor with 16, or more cores.
	this doesn't imply that code cannot be written portably, but at some
	points the usage of the language will run into the hardware. the point
	of the language being a systems language is to provide language support
	for programs that want to interact directly with the hardware in a way that
	is as portable as possible. so cross compilation is a assumed use case, as is
	conditional compilation.

	rehostability is running the compiler itself on different architectures, and that
	problem is one of good old fashioned hard work. the way that we garuntee 
	rehostability is by way of making the kernel all that is needed to build anything
	you could need in the language, and making non-critical components libraries.
	so all one needs to rewrite when retargeting some other hardware is the kernel.
	(that may also be unnecessary if we bootstrap the language through LLVM, or
	 if we write it in portable c/c++.)

- Implementation
	the language needs to be able to exist to be useful, so creating it
	is pretty important. that may seem idiodically obvious to say, but actually
	getting things done in the first place is hard, and the greater world is a
	very unpredictable place. concerns raised from difficulty of implementation
	will definetly have an influence on the final design.
	
	the first compilers
	were written with severe memory constraints, and the design was influenced
	by that, both of the compiler and of the output code. the compiler that
	is currently being written has virtually infinite memory.
	(especially wehen compared to memory constraints in the 1950's, 60's, and 70's.)
	so that will have an influence on the design as well.

- Security
	The language doesn't exist in a vacuum, a robust, expressive language
	should be aware of the security concerns of a modern language. C is famously 
	exploitable because it is hard to write hardened code,  More complex languages
	are exploitable because their own operation is hard to understand, and
	security is hard in a general sense because it is easy to exploit interoperations
	between disperate programs. so how can the language help programmers write
	hardened code?

- Language Interoperation
	Our langauge must exist, and so it has to contend with the other languages which
	already do so. How can our language interoperate with programs written in other 
	languages?


- Deterministic resource utilization:
	the static semantics of the language should use
	resources (time and space) deterministically, 
	and with an eye on keeping the runtime small.
	if you don't ask for it, you don't get it. 


from our perspectives and goals we can define points of friction and points of harmony.

	for instance, during the optimization pass, the compiler can optimize against
	time, or space. but not both, as fast data structures tend to be large, and
	compact representations tend to take more time to interpret their meaning.

	and to point to harmony within the language goals, Orthoginality is a feature
	of the language that helps expressivity and communication.

	and to point out friction, performance and portability are often at odds,
	becuase the most general version is often the most portable, but the least performant.
	and the most performant algorithms tie themselves close to the hardware, making them
	the least portable.
	
the design of the langauge.
the shape of computer languages is shaped by a few key design descisions.
declarative or imperitive?
	-> and a further choice for imperitive languages: garbage collected or not?
		(declarative languages must be garbage collected as far as I know.)
pass-by-value or pass-by-refrence?
static typing or dynamic typing?

and to a finer semantic point:
polymorphic types?
static or dynamic scoping?
lazy or strict evaluation?
...? and more questions than listed here

self - (pink)





state - (atoms)

primary data-types: int, real, text, bool, byte, word, etc.

static type system.
	name and/or structure equivalency depending on context.

lexical scoping.
	with c-like scoping and lifetime rules
	(new local scopes are dynamic, 
	 seprate functions get static scopes.)

out of order declarations, use a name before defining the name.
	// to support out of order decls, the language will need to 
	// define a known failure case: "The refrenced name didn't exist xor have defined type".
	// this failure will be signaled whenever the programmer uses a name
	// that has not yet been defined. (this could be signaled by a specific dummy
	// type that is only known internally to the compiler, Used BeFore Definition: UBFD,
	// or we could use exception semantics, either with some form of scheduling whereby
	// we could reparse statements that failed with the known case will give the langauge
	// out of order declaration semantics.)
	// once the name is defined at some later point, the program could
	// go back and fill in the type definition (create the binding).

sum and product types. (record and union respectively)
	in a tradidionally functional style.
	where a union can be tagged by the implementation.
	(this has the effect of reducing maintinence on tagged union structures,
	in both maintaining the tags themselves, and the using of the tags.)
	but with c style semantics for how the memory is layed out.
	(this allows programmers to have more direct control over the layout
	of their memory)
	we will also allow for bit fields in both records and unions

	a common pattern of use for unions is to treat the same memory
	as a different type to better support generic functions over 
	a range of types. (the range the union supports) to disambiguate
	between which instance of the union we have, we need to rely on
	(generally) tags. which are stored in the same location no matter
	which instance of the union the object represents, so programmers
	can say if(this-version) ... else if(other-version) ...
	and the compiler can generate code which disambiguates between instances.
	this feels like such a basic pattern of use that the compiler could generate
	some of the boilerplate. which is exactly why tagged unions will be a primitive 
	entity.

polymorphic type constructors.
	so we can support generic types better.
	

arrays and tuples.
	because arrays are neccessary, and
	tuples are really semantically convienent

pointers.
	an absolute necessity in a pass-by-value
	language, to support non static features.

owning pointers.
	this is a semantic convienence, whereby we
	offload the maintience of deep copy constructors
	and deep assignment operators.
	if you have a plain pointer, the language will assume
	that you will be using it as a non-owning refrence to
	some memory, in shorthand this means regular pointers
	will have mostly c's pointer semantics, whereby we are talking about
	the addresses when we copy, compare, assign, or construct.
	and when the programmer has an owning refrence we assume
	they want to maintain this as a refrence to a new dynamic object
	everytime. so the compiler can then assume they want deeply copy the structure they have
	when the user requests assignment or copy-construction. in this way
	owning pointers will be able to be treated by programmers like
	they would treat variables in python.
	when we copy, compare, assign, or construct, we will create
	a new exact copy in memory and assign it to the owning refrence.
	so two owning pointers will ~always~ point to separate instances
	of the type.
	and a regular pointer may point to a separate instance
	or may point to the same instance as another pointer.

	this subject sort of naturally leads to questions about the semantics behind
	returning, assigning, copying, and constructing owned vs. not owned refrences, 
	and to accessing members of	coposite types when we are talking about a
	static variable vs a pointer. 
	so a static variable should be able to be treated in the same way
	we treat static variables in c, we can preform defined operations
	and functions on variables, and their values are passed into functions
	who contain separate storage for that type/value per invokation. 
	an operator of particular note is the dot '.' operator.
	using which we access the named members of a record or union type.
	I feel that the dot operator should be overloaded by the compiler for names which are
	typed as those records and/or unions, and typed as pointers to those records and/or unions.
	so if you have a single refrence pointer you can use the dot operator to access the
	members of the pointed to object, instead of having to explicitly use
	the indirection operator once (or specifying a new operator and having two separate
	code bases for dealing with static or dynamic memory like c)

	this raises some questions about macro or polymorphic function instances when
	the macro or function is relying on the semantics of a nonowning ptr, or
	relying on the semantics of an owning ptr. like "this algorithm relies on
	the assumption that it is dealing with multiple refrences to the same object,
	if you passed in something that always does a deep copy on assignment that will break it."
	I say, that's a use-case for constraining your polymorphic variables with
	some code which can reflect over the types that are being used to instanciate it
	and make sure the user gave nonowning refrences.

	

None type, Optional Type, Any type (can only exist with refrence semantics?).
	a None type representing the empty set useful in many programming idioms, 
	an optional type representing either None, or Some type. whcih better represents functions which can fail.
	a refrence Any type, simply to provide a syntactic style more closely related to C, and
		because I don't know if parametric polymorphism plue optional types will allow the language
		the requisite tools to solve all possible low level coding problems. My assumption is that it will.
		but if there is any edge cases i don't know about, my assumption is the equivalent to
		a void* would allow the language any semantics it couldn't otherwise recreate from C.
		to still remove null refrences from the language, the defining occurance of an any pointer
		must be associated with some valid memory.




behavior - (functions)

assignment semantics.

functions are typed from the name, number, and order of it's arguments.
	multiple returns can be supported by passing a tuple.
	strict argument evaluation

arguments can be polymorphic.
	for parametric polymorphism 
	(what c++ calls 'templates')

pass-by-value semantics
	with pointers for refrence semantics and dynamic memory.

memory manipulation.
	the language will need to be able to write to and read from any memory location
	with impunity at some point. this is needed to implement low-level computer systems.
	with these semantics it becomes possible to implement drivers for hardware components.
	which be written portably on top of lower level semantics that were conditionally
	compiled like in C.
	the semantics that pink has access to are more expressive than C, and
	so it follows that we would be able to write a more expressive inteface on top of what
	ultimately would be the same low level semantics. which is precisely the motivation for
	writing pink in the first place. a richer set of semantics then that afforded
	by C, but still following in C's footsteps of being, A) A Portable Assembler, and
	B) having as small a runtime as possible.
	
	the intention of pink' is to increase the
	semantic richness of pink, while adding nothing to the runtime. because 
	macro expansion happens at compile time. with pink', libraries can reach into
	the kernel of the language and add features which can then be used as
	primary concrete entities by a programmer who #includes the library.
	
	
	(something like an #uninclude seems a bit trickier, until you consider
	it as name hiding.)

	aside:
		in my opinion the semantics in C that enable it to be a systems language are
		bitwise operations, assignment operations, arithmetic on pointers to arbitrary
		memory addresses, a small language runtime, and being turing complete. 
	
		to take this language from okay to production quality.
		one only need add some conception of threads, processes, locks & semaphores, file systems,
	
	
		maybe then the language could be further extended with a library of the
		most used data-structures, and basic drivers for
		each of the hardware peripherals you want the system to interact with.
		some default TCP/IP stack or sockets, UART, SPI, etc.


	we can now recognize that the null refrence was a design mistake of
	early computer languages, (https://www.lucidchart.com/techblog/2015/08/31/the-worst-mistake-of-computer-science/)
	
	but how can a systems language that doesn't have null refrences work?
	if you know c code, you know that typecasting a void* is how most
	c programms add more expressivity and flexibility to their functions.
	the common operations on c pointers that i know are

	using a void* to operate on memory in a typeless way. used in situations
	when you only need to know about the size of the memory you are pointing at.
	this pattern is used to implement functions like pthread_create,
	malloc/free, and qsort().

	you can have one function that operates on a union of types, and through
	checking a tag you can choose which cast is safe to do.
	I use this pattern in my code, but it isn't always used.

	well, you cannot have a pointer that points to null,
	sure. but what if pointers are idiomatically always wrapped in an optional type
	(or, this is a use case of single inheritance, wherby a pointer 'is-an' optional type)
	, whereby
	we either recieve a valid pointer, or the type of the entire expression is None.
	that then allows the language to leverage it's own type system to solve the problem
	instead of subverting the type system. if every construct in the language that
	deals with pointers is forced to make this design descision, then we can automate
	the making of it, by having interaction with optional types a default use case
	for conditionals across the language.
	this saves us from having to, in the same way as C, implicitly convert ints, floats, chars,
	and pointers to booleans and then you can say things like if(some-ptr) then ... else ...
	with optionals semantically it still means, "if this is a valid pointer then ... else ..."
	but done typesafely and explicitly, instead of not typesafe and using implicit conversion.
	a pointer could still be thought of semantically as storing the address of another entity,
	and then we can remove the special case of a pointer to address zero being
	a nullptr. a non-valid pointer is always signaled by never returning a pointer in
	the first place. so you either have some usable type, or you have a None type.
	
	treating the location as either a source or a destination semantically will imply
	reads or writes on that memory location. this is a nessecary semantic meaning.
	we by nature of being a systems langauge, have to allow statements like
	write this byte to this address.
	because that is the way in which systems work at an assembly level
	and we want the thinnest layer of semantics possible over assembly.
	however we don't want to be tied to any	specific assembly,
	because we simultaneously want to support every specific assembly.

	because the memory addresses are always defined in some meta-material like
	documentation, the language has no way a-priori to ensure that any operation
	on a pointer will be safe. and because the language further cannot know what
	the programmer themselves intends to do when they read to or write from arbitrary memory.
	the language cannot ensure a-priori that these are safe operations.
	so we need to give programmers the tools to specify exactly what those intentions are
	and to specify what those safe vs. unsafe operations are.
	we cannot know if writing a logic high to some location will cause bus contention for instance.
	the programmer knows these semantics, and in trying to interface with
	the hardware they have, will have to enforce arbitrary constraints by the very behavior
	of their program in order to ensure correct operation. so why not give them the tools
	to enforce those semantics on users of their code

	if that makes no sense, lets try a real example:
	say you wanted to write a driver for some specific harware component, a UART driver.
	lets say for instance that the UART component is accessed through memory mapped
	I/O. that is, there is a few predefined memory locations that the UART is writing to
	and reading from, and let us further say it is in the form of a contiguous
	section of machine words (as it is in a MIPS microprocessor.)
	again for the sake of argument, we could say the first word
	is a status register, the second an input to the device, and the third an output.
	the programmer could for instance, define a few simple semantics such as,
	get me the status, get me some data from the UART, and write some data into the UART.

	a programmer who wants to interoperate with the UART will need to check it's
	status before they can read or write data, to ensure the device is not currently busy,
	and/or that the data they read is valid and when they want to send data they may also
	have to follow some procedure.
	the naive programmer would/will very easily misuse the simple semantics,
	and overwrite or otherwise misuse the device, causing bugs or worse, hardware failure.
	
	if you want to write programs in a compositional way, you define simpler
	abstract semantics over more complex underlying structure. this allows
	those who want to use the complex underlying structure but don't
	neccessarily need to know how to use to simpler more abstract semantics.
	which can dramatically simplify the code in other portions of the program.
	(if done well; when done poorly, the broken semantics seem to infect
	 the rest of the program, causing the need for more complexity everwhere.
	 like was observed with GOTOS, and NULL refrences.)
	
	to go back to our example:
	so we need to either wait for the UART in a busy loop (usually not the best idea)
	or we need to decouple reading and writing to the device in time
	from the other operations of the program. This can be done in a variety of
	ways and any choice you make has a significant effect on the shape of the code 
	you write. are you writing coroutines? threads? interrupts? some master busy loop
	which checks each device in turn? in each case the code looks dramatically different
	from the others. the language is here to help programmers engineer abstractions
	to help futher users to use the underlying hardware in a manner that lets them
	be expressive and safe in their use of the hardware.

	I feel that the langauge could provide some form of a 'device' abstraction
	that could unify the usage of memory mapped IO over some defined (paramatized)
	semantics. (you provide the rules which garuntee proper operation)
	or maybe, multiple abstractions which parametrize each of the approaches so one
	could easily utilize them in your program.

	and I feel that you could state those semantics in a macro.

	and if you didn't want the abstraction? well, the original semantics would
	and should also be possible. just build on top of the bare langauge, or
	write your own abstraction which meets your needs. 
	if you are writing your own you can leverage the semantics of the existing
	language, and the semantics behind extending the language.

	

--- advanced features ---

macros
	define new kinds of atom, and new kinds of behavior.

	
compile time reflection over built-ins and defined types.

compile time interpretation

exception semantics

coroutines.
	which will help implement harware interrupts. i think.
	hardware interrupts can almost be considered coroutines
	themselves. 

threads

files