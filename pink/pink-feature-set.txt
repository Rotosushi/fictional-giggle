
thesis,
	so, what is the minimum viable set of features in a given programming language?

first,
	what is a programming language composed of? 
		-> state and behavior.

	what does a programming language need to talk about?
		-> itself and its environment

		divide the language into four quadrants (state <-> behavior, itself <-> environment)

		
				|state				| behavior
----------------|---------------	|------------
				|	vars, constants	|	functions
		itself  |	internal context|	function call
				|	new types		|	primitive behavior
----------------|---------------	|------------
				|	proccessor state|	OS/library functions
	environment	|	OS state,		|	other programs
				|	Hardware state	|	internal/external hardware.

		note:
			divide the language into four quadrants (primary <-> composed, concrete <-> abstract)

			|	primary (an entity that cannot be decomposed			|	composed (an entity formed of primary and
			|				at the current level of abstraction)		|				composed entities)
------------|-----------------------								----|------------------------
			|	functions&macros:		| atoms:						|	function:				| atoms:
concrete	|	=, +, *, cmpxchg,		|	int, real, text,			|	  push, pop, peek,		|   stack, queue, list
 provided	|	typeof, sizeof, [],		|	predefined constants		|	  prepend, append,		|   map, set, file,
 by the		|	if, while, print		|	[], *, !*,					|	  open, seek, fork,		|   socket, thread,
 language	|							|								|
------------|-----------------------								----|-------------------------
			|	functions:				| atoms:						|	function:				| atoms:
abstract	|	macro, fcall,			|	local & global vars,		|	fn,						| type (adt),
 written	|	 						|								| 
 by the		|							|	local and global consts		|
 programmer	|							|								|


		note:
			the language needs to have semantics for dealing
			with a variety of situations. some situations
			will inevitably be unforseen. in order to react
			to changes in the abstraction layer, implementation details,
			or requirements, the language needs
			to provide facilities for upgrade and modification
			directly, at all times. this gives a future user of the language
			a direct path to upgrading/extension that is the same 
			as a current programmer. (a program compiled by the language however,
			does not inherit this implicitly.)

			inevitably the solutions that were implemented become obsolete for some reason
			(or maybe they don't, lucky you),
			
			maybe for effeciency, maybe for buggyness, or maybe because requirements changed.

			in any case modifying or replacing what already exists is always
			a challenge. so shouldn't your tools provide you with resources
			to make it easier to upgrade and modify not only your code,
			but the tools you use to create in the first place?
			
			a programming language can in many ways be thought of as a set of language primitives,
			interacting according to a set of rules. the friction points of program implementing/maintaining/upgrading/extending
			become the interactions between the various sets of rules and primitives in the language.
			(interactions being used here to broadly name all of the syntactic changes
			that need to be made, and the subtle semantic changes that need to be reconsidered when 
			implementing/maintaining/upgrading/extending programs;
			 these things can become combinatorially or exponentially complex quickly.)

			in a closed language these interactions or 'friction points' only need 
			to be contended with during implementation/maintinence/upgrade/extension  
			of the languages primitives and only by the languages programmer. code that
			is written in the language, by users, relies upon the primitives that the
			language provides in order to implement/maintain/upgrade/extend their own
			programs.

			however in an open language the friction points have increased by at least a magnitude
			(of whatever measurement scale is used)
			just by the nature of allowing users to extend or modify the language source
			directly. who knows, the risk of misuse may outweigh the benefiets gained.
			but that is not a question that can be answered when considering the
			issues in the abstract. it would be ideal design pink' such that it
			provides consistent and known features to create language extensions,
			something like a grammar kernel. whereby extensions can be written without
			having to redefine previously existing features, this would go a long way
			towords allowing something like implicit interoperability. just by having both
			programs use the same primitives. to say that another way, all user written
			semantic extensions are composite.

			note:
			theoretically this kernel could be used with user grammars to describe
			other languages entirely, such as a LISP dialect, or Python, or something
			else. This just justifies the exploration of this feature even more for me,
			given that it has as much potential.

			pink' may be extended to support LL(k), LR, or LALR grammars.
			maybe pink' will understand a DSL that has been custom tailored for describing 
			the front end of a language while utilizing the common kernel. 
			so entities that already exist can be used with new entities
			by means of their using a shared set of primitive graphemes.
			this pushes the entity cooperation problem into the language kernel
			itself. where it can be dealt with in a constrained environment.



state we will call atoms.

behavior we will call functions.

both (atoms + functions) we will call entities.

entities have three important attributes
	name
	value
	type

the name is how we refer to entities in our programs

the value is the encapsulated state of that entity:
	-> for functions this is the body of the function
	-> for atoms this is the memory associated with the name

the type is the encapsulated behavior of that entity:
	-> for functions this is the set of inputs mapped to the set of outputs
	-> for atoms this is the set of valid operations upon itself (this evaluates to a set of functions)

we can distinguish entities by two dual pairs of category: primary <-> composed, concrete <-> abstract

an entity can be either primary, or composed.

	a primary entity is a building block of the language.
		a primary entity is any entity that cannot be decomposed without
		 having to descend a level of abstraction. (i.e. the programmer doesn't
		 worry about implementing fn '+'(a: int, b: int) -> int, to do so would
		 require assembly, which descends a layer of abstraction and ties that
		 program to a specific hardware.)

	a composed entity is an entity that has been constructed out
	of other entities. 

an entity can be either concrete, or abstract.

	a concrete entity is one that has been written by the language
		implementer.

	an abstract entity is one that has been written by the user of
		the language, the programmer.

at first blush it may appear that the distinction between a
primary entity, and a concrete entity is unneccessary. however,
the distinction does have to account for the situation of syntax
and semantic extensions to the language. 
by which means a programmer can construct a new primary entity
that is in fact not concrete. (also in this case the programmer may very 
well have to concern themselves with the implementation of
fn +(a: int, b: int) -> int, though it is hoped that by having the
basics of the language in place, the programmer can rely on already
defined grammar primitives to define further language primitives.)
(it is up to the reader to think
of other ways in which this distinction is relevant.)


1: the kernel
the kernel of a programming language is composed
	of it's primary concrete entities. it should be
	the minimum set of concrete entities to express
	all features of the language. there will be plumbing
	underneath, but that will be handeled by the implementation,
	the set of primitives that the user has access to without
	#include'ing or #require'ing should be sufficient to program
	all of the language.

2: the construction mechanisms
the construction mechanisms of a programming language are the means
	by which new entities are created. (i.e. we describe algorithms 
	in pink using 'while' and 'if' statements, we describe new symbols
	by declaring them and their type, or their type constructor.)

3: the abstraction mechanisms
the abstraction mechanisms are used to describe new
atoms and functions. by which further entities can be constructed.

4: the extension mechanisms
the extension mechanisms are the means by which the syntax or semantics
of the language can be extended. this is the means by which the programmer
can add new elements of the language to the language.


1: the kernel of pink
	q: what goes into the kernel of a programming language?
	a: the smallest set of entities which when considered
		interoperating with one another are capable of
		describing the features of the language standalone. then
		porting pink, becomes a matter of porting the kernel,
		and everything above can be described without considering
		the actual hardware  this is the same mentality that made 
		c portable. this won't extend to all of the facilities
		of the language, as there are considerations to the actual
		hardware in some places. 



------------------------------------------------------------------------------------
	q: so what goes into the kernel of pink?
	a: 
	primary type primitives:
	name:
		int, real, text, bool, bit, byte, word,

	value:
		integer, float 32/64, unicode array, boolean, bit, 8 bits, machine-word size (32 or 64 mostly), 

		reasoning:
			these basic types, int, real, text, and bool, provide facilities to describe many
			of the daily tasks of programs. when we are interacting directly with the hardware,
			oftentimes it is neccessary to be precise with the size of our datatypes, this is what
			the u8/16/32/64, s8/16/32/64, f32/64, byte, half-word, and word types are for. 

		note:
			unlike c, pink provides a text primary datatype.
			this is an example of the difference in the philosophy of the design of the language.
			in c, the reasoning behind not providing a 'string' primary concrete datatype
			is that the overhead of string processing is a lot (and should be something
			that the programmer has to be explicit with), null terminated character arrays
			had direct support in the assembly language for PDP-10 and PDP-11, and null-terminated
			strings consume less space than storing the length.
			so, it's 2019, and a few things have changed since then, namely, unless you are
			working on a small microprocessor, you don't care about the overhead of string processing,
			and unless you are working on a small microprocessor you don't care about the memory
			overhead. (here 'you don't care' should be read like 'the overhead is minimal for
			the usability gained') you will need string processing on (nearly) every system,
			so this is something that is a no-brainer for inclusion in the semantics of the
			language. The only thing c really gained from it's descision about strings is
			a reputation for nasty bugs and security flaws.

	composite type primitives:
		[], (), adt, *, !*, **..., !**...,

		array type, tuple type, ptr type,
		owning ptr type, ptr to ptr, owning ptr to owning ptr. 

		reasoning:
			 when we do memory management, we need three things. refrences to memory,
			homogenous memory definitions, and heterogenous memory definitions.
			 we need some way of talking about memory that is somewhere else,
			that is what pointers are for. we need some way of talking about
			regions of memory, that is what arrays are for, and we need some way
			of talking about blocks of memory (with type), and this is what 
			algebraic data types are for. 
			 sometimes it is convienent to group
			things anonymously, or to talk about pairs of things, and this is what
			the tuple is for. (the argument list and return list of a function can be
			represented as tuples for instance.)
			 if we allow functions to return tuples then we can remove the asymmetry of
			 function definitions. given that the language is LL(1) will probably
			 mean that we won't have a nice syntax around returning a tuple. just
			 due to the limited expressive power of LL(1). in v1 of pink, this
			 is an easy tradeof to make, as ease of implementation is a bigger issue
			 that ease of use. 
	expressions with precedence.
		reasoning:
		 having an infix notation expression statement with 
		 user definiable and overloadable procedures
		 allows programmers a syntactically light, grammatically
		 unambiguous way of composing procedure calls. that isn't
		 just: f(g())
		 because sometimes that gets awkward. (ofc f(g()) will also be supported)

		precedence table:
			lowest
			assignation
			boolean eq, neq
			boolean less, less-than, greater, greater-than
			boolean or
			boolean xor
			boolean and
			bitwise or
			bitwise xor
			bitwise and
			bitwise lshift, rshift
			add, sub
			mult, div, mod
			procedure evaluation (unary functions(a.k.a prefix functions), postfix functions)
			highest 

	(i am a big fan of some haskell features; infix any two arg function with ``
	and prefix any operator with (), also defining new and overloading existing operators.
	also, `` just ~feels~ like a macro to me. ofc there are issues when one considers type,
	but that is what the static type system is for!
	???maybe function names just have an extended char set to include common symbols.???)
	
	common functions that are needed in a systems programming language:
	arithmetic primitives:
		+, -, *, /, %, -
		
		add, subtract, multiply, divide, modulo, negation

		binops: +, -, *, /, %
		unop: -

		reasoning:
			math is one of the most common operations in programming, second only to boolean logic.

	boolean logic primitives:
		==, !=, >, >=, <, <=, &, |, ^, !

		equal to, not equal to, greater than, greater than or equal to,
		less than, less than or equal to, and, or, xor, not

		binops: ==, !=, >, >=, <, <=, &, |, ^
		unop: !

		reasoning:
			choice is essential, booleans facilitate choice nicely and mathematically
			understandably.

	bitwise primitives:
		!!, &&, ||, ^^

		not, and, or, xor

		binops: &&, ||, ^^
		unop: !!

		reasoning:
			this is a systems programming language, bitwise operations are often very
			convinent when interacting with hardware at a low level.

	
	language primitives:
		=, &, *, [], (), ., #, if, else, while, do while, typeof,
		sizeof, 

		assign, address of, derefrence, array access, function call,
		member access, comment,

		binop: =
		unop: &, *
		postops: [], (), .
		grammar construct: if, else if, while, do while
		kernal function: typeof, sizeof, 

		reasoning:
			there are basic operations one needs when working with
			the above abstractions. we need to assign values to variables,
			working with pointers requires address-of and derefrence,
			working with arrays gets a nice syntax over the pointer
			math via [], function call is required, . is needed for named
			member access. then we need choice and repitition. 
			the size and type of something is something we are often concerned
			with, i think there will be more *of functions when the language
			is in place. threads are a must when considering a systems language.
			the main thread is not the only place to get work done.
			

	construction mechanisms:
		:, ::, :=, create, destroy,

		static memory allocation: :, ::, :=
		dynamic memory allocation: create, destroy

		reasoning:
			in only the smallest microprocessors will there be no
			dynamic memory management (and in those cases the programmer can
			just choose to use a restricted subset of the language) otherwise,
			programs use dynamic memory constantly. it is one of the main
			concerns of the language. it can be said that 'computers are just 
			machines that move memory'

		note:
			so thats local, and module scoped variables and constants,
			 and dynamic allocation functions. pink will also need to
			 be able to describe globals and thread local storage.
			 pink will also be able to utilize multiple allocation
			 strategies. pink will additionally need fixed width types
			 (u8/16/32/64/x, s8/16/32/64), in order to support
			 8 bit, 16 bit, 32 bit, and 64 bit machine word sizes.
			 Named address spaces (corresponding to different memory spaces
			 in the machine) to support varied memory architechtures.
			 pink will also need to support direct hardware access.
			 fixed point types might also be a useful feature.
			 (it also seems like a prime feature for the macro system)

			it is my opinion that having direct access to the language via macros
			 will allow library and language designers the ability to
			 create better abstractions for describing hardware interface,
			 program structure, and program execution. it will also allow
			 the language to better support exotic features without having
			 to bloat the default language, don't use a feature? 
			 the language won't even try to parse for it.
			 (that last statement may be true for libraries, but the
			 kernel of the language will always have to exist)
			 (iff there were some grammatical kernel in pink'
				then pink could leverage that to interact with the
				hardware, then the programmer could define another
				abstraction at a later date

			 a systems programming language definitely
			has the ability to interact with the hardware directly, and to handle programmer
			specified assembly. it would be really cool to have the programmer
			be able to use the more esoteric parts of the assembly as well like
			cmpxchg and what-not directly, and type-safely. like, using the
			word and half-word datatypes? (or int or maybe anything that is
			sizeof(anything) == sizeof(word) ??) 

-------------------------------------------------------------------------------------

		

	abstraction mechanisms:
		fn, adt

		defining a new function, defining a new type,

		pink will have polymorphic functions and types. as well
		as function overloading. overloading and polymorphism work
		with the syntax of programs and help programmers define
		entities more effeciently and ergonomically.
		overloading is seen even at the lowest level where the same function
		'+' can be described for three primitive types: int, real, text.
		polymorphism is useful when defining data-structures.
		both are extensions to the type system.

		note: 
			I feel that a static typing system makes development easier,
			by eliminating entire classes of bug from occuring before
			the program even compiles and by giving you an explicit list
			of errors that serves as vital debugging information. the
			benefiets of the static typing system are increased by at least
			a magnitude when you consider that every macro can be typechecked
			both during expansion and when an instance of the macro is 
			declared. (and when you remember that one of the main problems with
			c/c++'s preprocessor is that it is untyped in both cases)
			
			algebraic data types seem like
			the most natural way of describing the sum and product types,
			which when considered with pointers, are the basis of every data
			structure that I know of.

			 optional typing
			gives a uniform way of describing the error case with a nil value,
			for functions whose return type is primitive or a ptr. this instead can be
			the hinge by which implicit boolean operations work. 
			instead of the c like, zero is false every other value is true.
			
			what if we remove any syntactic notion of a ptr.
			but don't remove the ptr semantics

			if we use the '.' operator for both regular member access
			and pointer member access (instead of c's use of the '->')

			and we check ptr == nil instead of ptr == nullptr
			(and additionally there is no notion of a 'null' pointer,
			there is only a pointer to some valid address or no pointer
			at all?)
			and we check var == nil instead of var == 0

			so you could then write
				value == nil 
			and not really consider if the name is dynamic memory
			or static memory, but the boolean check would work either
			way. because they use the option type either way.

			how useful would this be? does this clean the syntax
			and make it more legible? does it make it less legible?


	extension mechanisms:
		macro,

		defining a new primitive entity by some rules dictated in the
		grammar defining macros. sometimes a feature requires
		a lot of low level access to work properly. sometimes new abstractions
		need to be built in order to talk about new entities. this is seen with
		threads, this is seen with interrupts, and this is seen with exceptions.
		(additionally; exotic primary types, exotic memory layouts, direct
		 interaction with the hardware of a system,)
		these places are where the language needs to be extended in order to add
		or modify features of it. in order to facillitate these extensions
		addition to the language, the language will itself be able to be extended.
		from within the language itself.

		interestingly, you could define dialects of the language, and enforce
		their use using nothing more than a #include or #require.
		
		the language that pink is written in will be reffered to 
		as pink prime (or pink') pink will be a compiler written by specification.
		and that specification is what will be extended in order to fully implement
		a macro. pink' will be a LL(1) parser generator (in it's first iteration)
		capable of reading in an attribute grammar style specification language.
		this specification language will essentially be a DSL for creating
		LL(1) compilers. it will also be that programmers could specify a file
		containing a grammar extension.

2: the construction mechanisms
the construction mechanisms are used to create instances of
entities in the programming language. they are the primary entities
which describe local variables, file scoped variables, global variables,
dynamic memory, and the control the flow of functions. meaning this is also
where they call functions, operations, OS operations, 
and where they interact with the hardware.

3: the abstraction mechanisms
the abstraction mechanisms are used to describe new entities in
a programming language. these are the primary entities which are used to
declare new functions and atoms. this is function headers and the 
algebraic datatypes.

4: the extension mechanisms
the extension mechanisms of a language are the means by which a programmer
can specify a new abstraction mechanism. by which new kinds of entity may be
derived. this is the mechanism by which new macros are written within the language,
where new language facilities are written, and where new language dialects and
other languages entirely can be described.

these are the four pillars of pink;
	1: the kernel, by which we acheive program portability
	2: construction, by which we specify our actual programs
	3: abstraction, by which we specify new entities in the language.
	4: exstension, by which we specify new kinds of entity.

	note:
		one must consider the interoperation of all entities within a language,
		but this is a question that cannot be answered in the abstract,
		from an initial design perspective.
