


conceptually, a program is composed of a set of functions, and a set of atoms,
	existing within an environment. this program can be 'executed' by following
	the series of statements following from the root function of the program.
	when the end of the root function is reached, the program will return.
	(pass control to the caller)

atoms are used to refer to state within the program,
with the name and 'type' being used to disambiguate between atoms. 

functions are used to refer to behavior within the program, with the name
and argument list being used to disambiguate between functions.

the environment is a tricky thing to pin down, as we play with it
constantly, but always implicitly. the environment
of the code is everything visible to the current flow of control
one is thinking about. this in essence means that if you were to type a 
name where grammatically an entity is to be expected, the
compiler is going to use rules to search the current environment
to resolve that name. all of the valid names one can type in a given
environment are considered 'in scope' and compose the entirety of the
current environment. we like this, because we want to reuse names in
local scopes. we also like not messing with other functions
static memory accedentaly via names.

so, a program is in essence three abstractions, atoms, functions, and IO.
how do we describe and create instances of these abstractions?

for atoms we are concerned with memory layout and type.
algebraic data-types and the assumptions of c's struct and
union upon memory should allow expressive and deterministic
layout (which is the goal of anything the language uses to
describe atoms). the type of something is described by the set of
functions that have an argument of that type. which is to say
that operate upon, or using atoms of that type.

for functions we are concerned with encapsulating some behavior,
and providing controlled/expected modification of the algorithm
via the functions arguments. we describe any algorithm
using three things ';', if-else if-else, and while. we 
compose seqeuential actions together using ';', we choose which
actions to execute with if-else if-else, and we conditionally
repeat actions using while. we can create syntactic sugar and/or
new constructs using the language extension facilities. (think,
switch statements, c-style for loops, etc..)

(the only difference now between program, and OS is that
 the OS is persistent after executing a program. when we
 let users start threads and processes, the only difference
 between the OS and what the user is doing is that the OS
 is what will continue running when the user process ends.
 so the language runtime will need to support all of these
 things, yet be as small as possible. seems paradoxical...
 )

for IO this is a more difficult question. this might be
confusing for inexperienced programmers. the matter of IO
is solved right? we have a primitive function, which comes with 
the language, and solves the problem for you (called print, or printf or cout). 
however, this is not the case in practice as the default print statement
quickly becomes unwieldy in complex code, for these cases
the language (or you) builds specilized abstractions that handle these cases
well, but preform poorly in some other aspect, and soon you don't
have one IO primitive, you have a library of IO primitives.
my problem isn't that you need a library of IO primitives
to solve the problem of IO in a convienient way given certain constraints.
it's that conceptually we haven't moved on from IO primitive, to
something more compositional, and maybe orthogonal to the other components
of the language? I don't know what that would be, maybe monads?

the primitives of the language, make up the core operation of the language.
every element that the language talks about will be expressed using 
primitive and composed elements. 

being a systems language, we are inheriting our execution model. this helps keep
the language runtime small (in time and space). what is that execution model? assembly.
well, a very simple imperitive language essentially. it can understand literal values
like Int and Float and Char, it has primitive functions like add two integers, or load and store values in memory
it has the ability to interact with the outside world by writing values to
specific addresses or by utilizing specific functions, you even get variables in a local
and global context via registers and in memory respectively.

what, you may ask, is the
benefiet of having the high level language if you are inheriting the same execution model? well,
first of all why are you asking this in 2019? i think we all like high level languages by now.
the problem with assembly is that is doesn't compose well together. that is, when you try
and write code that is going to interoperate with someone elses code, you have to know
too much about the execution of the other persons code in order to use it properly. (in
straight assembly, you essentially have to be able to write the code you want to interoperate
with if you don't have things like a standard calling convention and such. and establishing the
standard calling convention is something that we can get the computer to do, so why not?) this is a problem
that has been known for as long as computers have been around. (Djikstra himself knew about it
and subsequently wrote a very famous article about it, he hated GOTOs, fairly) the problem is best explained by the 
problems associated with the GOTO (there are other issues but they are subtler) and it boils down to this
liberal use of GOTOs make code impossible to read, debug, and maintain. 


there are three things required in order to evaluate any algorithm; descision, repition, and
sequence. all three of these things is expressed via one abstraction in assembly, the GOTO. the execution
sequence of the processor is only modified in one way, via a variable which says from which address
will the next instruction be pulled from and executed, called the program counter. so if you want to choose between branches of
an algorithm, you are really choosing between which address to next execute. the problem becomes
clear when we consider that there is no restriction upon which address we choose to execute next.
an unwitting programmer (or hacker) can enter into the middle of functions, into other programs entirely,
they may even write a malformed address and halt the machine. so clearly we need some
abstractions that will constructively/clearly modify the state of the machine, without allowing
for willy nilly code execution like with a GOTO. luckily this work has already been done to some
extent.

I do not presume to know what the best abstractions are for expressing the ideas needed in
a systems language. as a starting point, C will be used. this is one of three (four?) languages that
I consider a systems languages (that i know of)

C   - the OG
C++ - C's 'little' brother
D   - C++ but done coherently
? Objective C - I have literally never looked at objective c,
				but apple purports to have written their OS 
				in it, so... (i feel as if the lowest bowels
				are still probably in C, because the
				runtime is so small.)

I am picking C because it is the smallest language to work with, that's the biggest reason. 
This is something i would like to emulate even, as it makes porting easier. (because porting is a hard part)
the less code that needs to be written to get to a functional kernel,
the less code that will need to be repeated for every assembly language. 
(x86, ARM, MIPS, PowerPC, SPARC, RISC-V, and so on...)


I feel that the kernel that C lays over the assembly to be widely very useful.
the majority of tasks can actually be completed in an ergonomic way.
functions are largely okay, and so are variables. 
overall the sytax is akward in some places (switch scoping rules, header files, etc.),
and there are some quality of programmer life changes that could be made as well. (better syntax for declarations,
more type inference, more expressive type system) these things are not digs at the language,
C was designed in the early 70's we have learned a lot since then.
that is another point to pink and pink' I feel. When you are building something, anything,
you are going to make choices that seem unneeded, wrong or even harmful in hindsight, that's normal, 
because when you are doing something for the first time, 
you are not doing that thing from an informed position about that thing.
heck, even when you are making choices after doing it a few or even a thousand times,
you are working from only your previous history, new ideas and new encounters can happen at any time. 
you can be challenged at anytime! sometimes things need to change, to update.
this is just a part of the process. as this is a fact of the work, why not try and use the computer to help?
the compiler of any language will need to preform many of the same tasks, and all will need to translate or
interpret the syntax they parse. the assembly languages that the higher level languages target don't change 
nearly as often, so many iterations of the higher level language will target and run on the same version of
the hardware. so many of the tasks of the compiler are solved, and only the specific syntax and meanings need
to be changed? this seems like the perfect place for a language! (a domain specific language) 
where the abstractions we are building are a computer language described using a language! (how very meta!)

what if the runtime of any given program is generated by pink' for the specification, if it is dynamic, presumably
we could not include portions like a garbage collector, simply by it's inclusion or exclusion in the source file.
but like, at a grammar level with full type system support.
(or maybe this is not possible, and you would do that at a language level anyway, either way it should be supported
by generating the language runtime.)

then, if your source file doesn't use portions of the language, like the GC or reflection, these features can be optimized
out of the resulting executable's runtime, even if the full language supports it, because that specific program doesn't utilize it.
though, maybe i am speaking out of a place of ignorance.

I am starting to think that pink' will be a declaritive language.

------------------------------------------------------------------------------------------------

the paradoxical goal of:
"strive to make explicit all information needed to understand the execution of
the program, at all levels of the program. but not so much as to make the task of
writing programs too laborious."

variables are a name which is associated with some region of memory, which stores some
state. this state will always have a type in pink. the type is defined by the set of
functions which operate on that type. 

functions are a grouping of assembly statements which carry out the algorithm described
by the syntax of the language. functions have their own context which can be used to store
variables and other information. functions are where all the work of a program is done.
functions receive arguments, and return values.

functions are a great way to define actions compositionally. functions are really
the bread and butter abstraction of the language. 

prefer function call to member dispatch
	this helps to keep the physical structure of our data plain. (the plainer the representation,
	the more compact it can get in memory. sometimes you need a pointer tho, and that's okay too.
	the language should also provide good packing/unpacking facilities)
	helping us write generic funcs in the same vein as the operator+() family of functions,
	overloading 'coerce(type1, type2) -> type2' and such in the language.
	
	coerce type1 -> type2 ?
	
	type1 -> type2 ?
	
prefer polymorphism to type coercion and casting

make casting and coercion explicit, make promotion implicit

	-> casting makes no promises on the value after the transformation
		if casting a float to int results in a loss of precision for instance.
	-> coercion is done when precision is garunteed
		int to float, byte to word, etc..
	-> promotion is done 'under-the-hood' to meet hardware requirements
		simulating a byte with a full word


casting and coercion are both tasks who's goal is the transformation
of information. from the perspective of the programmer they change 
the type of the variables on which they act. this may or may not be reflected
in the underlying instructions which perform that transformation. but
that is something that should be hidden from the programmer in the 
name of portability. it should be able to be thought of as type transformation.
because we can optimize the transformation into zero instructions to cast 
between word-sized types does not mean that we should hide the fact that
the type transformation needs to happen. good design should strive to 
factor out as many casts as possible.












































