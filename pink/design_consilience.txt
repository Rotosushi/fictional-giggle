
so, programming is a brand spanking new engineering and scientific
discipline, and as such, we don't have as much wisdom of experience that
other disciplines have. Our hindsight abilities only reach as far back as the
the 1950's. earlier could be argued, but our modern idea of what
a programming language is, and could be, is largely rooted in the
conception of programming defined in this decade. the definition
that they went with, is that a programming language should consist
of some small understandable set of primitive constructs, which can be
composed together to create and describe larger and more complex algorithms.

we have some mechanisms which we understand, and we labor to create
new mechanisms described in terms which we already understand.
in this way, programming languages mirror real languages, as humans labor 
to create new meanings and to understand new things 'in terms of' what
we already understand.

in this way pink aims to be a programming language.
it aims to be a vehicle for writing what is new and unknown
	in terms of the old and known.

there is one peice of human language that programming languages often
fail to fully incorporate into their design, and that is that languages
are a 'living' thing.
in a human language, meaning is derived from use. if a term is co-opted
or overridded with some other meaning, the term can have it's definition
shift beneath it's feet. that is, the syntax now has entirely different
semantics.

now to reproduce this kind of behavior in a programming language would
be hell. for the writers, maintainers, and for users of the language.
nobody could get anything done because meaning itself would be indeterminite.

so, to move forward we agree that one thing has one meaning, 
and other things have other meanings.
if we think that one thing should have two meanings, then the meaning must
be derivable and unique from the context and use.

so then now, how do we approach this issue of 'living'?

if meaning derived from use is not constrained enough to be usable,
but any meaning we now come up with may be incomplete, or wrong, or
not make sense when applied in some new way. maybe even in some new
way, that didn't even exist when it's 'kernel' or understood semantics
was designed or implemented.
so then what can we do? 

the path that most languages choose, is that of versioning.
they say, the definition is 100% static. but allow for new versions
of the definition to be released at later dates. this gives them
the strictness and the flexibility they need to revise, update, upgrade
and otherwise change the meaning of things, while avoiding all of the
issues of the semantics changing beneath everyones feet. they say,
this means one thing here, under this version, and that is subject to
change in future versions.
I see nothing wrong with this approach for the long term, most of
the issues that I can see with the most senior of our programming
environments (linux and c/c++,  windows and c/c++/c#, 
and osx and c/c++/objective-c) is the unwillingness to throw away
what is bad about their products in the name of maintaining backwards
compatability. now, maintaining backwards compatability is generally
a good thing, as it allows users to leverage their existing understanding,
as well as their already developed tools and methods. but if a tool
or method proves itself time and time again to be usefull for nothing
but shooting yourself in the foot in clever ways, then why maintain
it's existance? overall this would seem to be a net drain on everyones time
and resources if they still have to solve the problem of how to interoperate
with every broken feature of the standard just to use the usefull 60%.

so, maybe the backwards compatability should be garunteed only 
for some well understood, well-maintained, and essential core,
with the rest then having to meet a litmnus test of practicality and
understandability. 

then any project is free to implement some hair-brained, esoteric,
but neat sounding feature in some version, and remove it from future
versions without breaking backwards compatibility for everyone. if
you only rely on the well-understood parts of the language, you need
not worry yourself over every new feature implemented.

(I am sure there are other reasons for breaking backwards compatability,
but for the sake of the brevity of this document, we leave those as an exercise
for the reader.)

now, if you are thinking of this from the same perspective I am, you might be
wondering, "hey, you made a big point of language's being 'living'
and then proceeded to explain how something entirely separate from "the
language is responsible for changing the language", what's up with that?"

well, that is exactly what I mean, the language itself is designed as
a static thing. version to version all that is changed is the languages
static definition. well, what about language features which allow you
to extend a languages static definition? (making the definition either
partially, or fully dynamic)

to the best of my knowledge there is only one language which truly
allows you to extend it's understood syntax, and that is LISP.
(not the OG definition of LISP of course, but it's descendants)
this is accomplished in LISP by way of LISP programms being the same
thing as LISP data. so LISP can operate on itself using the same mechanisms
by which it operates on data.

http://lists.warhead.org.uk/pipermail/iwe/2005-July/000130.html

source code generation is a notoriously difficult problem.

LISP solves a lot of the difficulty by unifying the syntax with the data being processed. 
everything is an expression, and all expressions get evaluated,
and every expression is represented as a whitespace separated list

if we want to speak about syntax, the form we use to specify it in imperitive
languages is Backus-Naur Form.




