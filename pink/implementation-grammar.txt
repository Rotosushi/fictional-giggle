
# variables of primitive type
# functions taking arguments, returning a list of values
# input/output via c++ stdlib
# computation driven by the grammar.

# set of possible attributes, given
# as a list of the form
# <id> ':' <type>
# we define our attributes, then apply them
# in a inherited or synthesized way.

# when considering implementation of the source code,
# consider the idea of a basic block, a section of
# code that has one entry and one exit. this,
# is the basic unit of execution. branches are
# branches between basic blocks, loops loop over
# basic blocks, and sequences of statements compose basic blocks.)

# each attribute could be implemented as a callback action
# to be executed when the match is completed.
# the function will take a varargs list containing
# each semantic element. 
# the type signature could be imagined as:

# fn attribute(production : ...) -> res : production_result_type { #{ body #} }

# because the result
# type is derived from the usertype of the rule the attribute is associated with,
# which isn't known until we parse user-code, the attribute could be a function
# template.

# then we could imagine the algebraic data type of a rule in pink'
# could look like
# adt rule = (lhs: name, prods: list(production), attrs: list(attribute))
# where a rule has a name, a list of productions, and a list of attributes
# for each production.

#{
	basics:
	<symbol>
	-> declares a new grapheme.
	   a grapheme can be either terminal
	   or non-terminal. terminal symbols
	   are the primitive tokens and text literals
	   which compose the language. each 
	   grapheme gets state associated with it.
	   Each production gets a series of rules that 
	   get executed before returning to the parent node
	   and after the rule has been matched successfully,
	   this series of rules is called the attribute of
	   that production.
	   
	   aside:
			is a grapheme who is composed entirely of non-terminals,
			non-terminal itself?
	   
	'literal token'
	-> declares a new literal text grapheme that must
	   be matched from the input stream. this declares a new terminal
	   symbol in the grammar.

	anything-else 
	-> every other token (that isn't
	   surrounded by '' or <>, or the tokens ':=', '{', '}', etc.) is assumed to be a part of
	   the language itself (pink'). it's a function name, or a variable,
	   or an operation.

	<symbol> := <symbol1> <symbol2>
	-> declares a new production.
	   each production exists in it's own environment, much
	   like functions. the lhs symbol declares a new non-terminal
	   grapheme. the symbols that appear on the rhs can be
	   terminal or non-terminal, additionally the symbols must match
	   exactly in the order in which they appear.
	   (i don't think we can allow the lhs name
	   to appear in the first position after the EQ? I think that symbol
	   must be terminal for the grammar to be LL(1).)

	<root> := ...
	-> every valid grammar, or grammar extension has some root non-terminal 
	   grapheme. the root symbol may never appear on the rhs of any rule. the
	   root symbol of the grammar is the computational entry point.

	<non-terminal-symbol> := 'terminal-symbol' <non-terminal-symbol> <terminal-symbol>
	-> terminal symbols are symbols who are literals themselves or something that
	   describes some literal text formatting. (maybe regular expressions?)
	   non-terminals are symbols who are composed of terminal and non-terminal symbols.
	   the LHS of any rule is always non-terminal. in order to be LL(1), the grammar must
	   be decidable by only looking at the left-most symbol on each step of the
	   computation of the grammar.


	<symbol> := ?()
	-> a term surrounded by ?() is optional,
	   meaning it will either exist, or be
	   nil if the production matches.

	<symbol> := *()
	-> a term surrounded by *() is an optional
	   list of values, that can be iterated over.
	   meaning it will either exist or be nil
	   if the production matches.

	<symbol> := +()
	-> a term surrounded by +() must match at least
	   once, and can match any number of times after.
	   it also can be iterated over. meaning if the
	   rule matched, it exists.

		aside:
			I want to allow multiple symbols
			to appear in recognizers like *(',' <symbol>), and ?('=' <symbol>)
			but after recognition, how do we refrence the symbols using the
			pseudo-variables in the attribute?
			my initial solution is to say each symbol in the production,
			gets assigned a number from left to right starting from 1,
			and +(), *(), ?() do not affect the numbering. then when
			we are reffering to a grapheme that exists in *() or +()
			you can treat the name like a list type. when you refer
			to a grapheme in *() or ?() you can treat that name like
			an optional type.
			like:
			<prod> := 'ts1' <nts1> *(',' <nts1>); {
				append (%%, %2);
				for (it in %4) append (%%, it);
			}
			so, here conceptually it seems like we need a list
			for each element occuring in the grouping. but that 
			may not be the case in implementation. (we could
			store just one ',', but still allow programmers to 'iterate'
			over it, whereas the <nts1> symbol would be a list of values,
			each element being the matched element.

			an alternative solution is to say that groupings 
			are treated like they are a grapheme, and the grouping 
			gets it's own pseudo-variable which then needs to be 
			split by another operation, maybe with pattern matching?
			like:
			<prod> := 'ts1' <nts1> *(',' <nts1>); {
				append (%%, %2);
				for ((g1, g2) in %3) append (%%, g2);			
			}
			this seems like a viable alternative given that pattern
			matching has other use cases.


	<symbol> := <production-1> | <production-2> | ... | <production-n>
	-> a term can be defined as a series of productions
	   each separated by |. each production gets it's own attribute.

	fn func-name (argument-list) -> return list {
		body
	}
	-> functions can be defined, and called in
	   the attributes segments. Djikstra's
	   Three (;, if, while) will be available, in some form
	   or another. (idk if imperitive or declaritive is the way to go in the
	   long run, my gut says that pink' will become declarative,
	   and pink will remain imperitive. but I know imperitive style
	   better, so ill be using that as my starting point.)

	   thought:
	   functions should have to be pure, and side effects should
	   be relegated to actions, which are the same as functions, they
	   just get to preform side effects. this separation is to gain
	   some of what functional languages get when they make variables
	   immutable, as it separates computation from modification. this
	   can allow the compiler stronger optimizations, and it is
	   fractally similar to CDL with it's four different function types.
	   TEST, PREDICATE, ACTION, FUNCTION.
	   CDL cares about two different aspects of behavior, failure and
	   effects.
				(TEST: can fail, has no effect
				 PREDICATE: can fail, has an effect
				 ACTION: cannot fail, has an effect
				 FUNCTION: cannot fail, has no effect)

	   in my opinion, having an optional type
	   encodes failure into the semantic definition of the function rather than
	   making it explicit with syntax. i prefer this, being able to formulate
	   semantics out of already understood syntax means the
	   kernel can be smaller plus the option type is a powerful pattern on it's own.
	   however, we cannot avoid side effects they are a necessary evil;
	   we have to write values at some point to be useful.
	   but writing values is the main cause of bugs in programs! you exclaim.
	   well, making side effects explicit in the syntax hopefully allows the compiler
	   to reason about them, like a functional language can. allowing the compiler
	   more optimizations and static analyses tools. which should give programmers
	   more tools to make those bugs easier to fix and harder to write
	   maybe it's useful to go so far as to define pink using monads, 
	   and just giving the language an imperitive veneer. I think the
	   simplest design of pink' may be using monadic style.

	   
	   functions are pure code, actions are impure code.
	   impure code can call pure and impure code, whereas
	   pure code, can only call more pure code. this enables the
	   optimizations around pure code, because all pure code
	   is defined to only be pure. so you will never 
	   unintentionally introduce inpurity to some
	   computation, as the compiler will complain.

	   impure -> impure
	   impure -> pure
	   pure -> pure
	   pure -x> impure
	   
	   which means

	   action -> action
	   action -> function
	   function -> function
	   function -x> action

	   thinking about optimization, there should be levels
	   but it should be organized around some assumptions.
	   i.e.
	   no optimization: should imply to the compiler 
		-> "I want you to output exactly that code which implements
		    exactly what the syntax defines." if one looked at the
			output assembly, one would see all entities implemented in an
			unoptimized way that mirrored as closely as possible
			what the programmer stated.

	   weak optimization: should imply to the compiler
		-> "I want you to output largely what i stated, but you
		    can preform small to medium optimizations on the
			source text to improve the speed of the computation."
			if one looked at the output assembly, one would see
			loops unrolled, variables reordered, functions
			inlined, and all the sorts of
			small and medium optimizations on the source text that
			a compiler can do, without fundamentally changing the logic
			that the programmer stated.

	   strong optimization: should imply to the compiler
	    -> "I gave you source text that defined some program
		    semantically, i want you to output the fastest program
			you can that behaves identically." if one looked at the
			output assembly of the program, it could mirror what the programmer
			said, or the program could be completely different. but in 
			operation the program would behave as specified.
#}


Attributes = {
	# the type system of v1 will only have type primitives,
	# and no way of declaring new types, so these types
	# are the only types which exist in the language. this is
	# to simplify the implementation.
	int_value  : int;
	real_value : float;
	text_value : string;
	bool_value : bool;
	value : (int_value | real_value | text_value | bool_value);
	type  : enum( NONE | ANY | MAYBE | INT | REAL | TEXT | BOOL | INFER );
	name  : string;

	# variable declarations
	declaration  : (name, type, assignop, expr);
	symbol_table : map(string, declaration);
	
	# function declarations
	arg : (name, type);
	argument-list : list(arg);
	return-list   : list(arg);
	scope    : (list(declaration), list(statement));
	function : (name, argument-list, return-list, scope);
	function-table : map(string, fn);

	# statements will be extendable in the final language
	# via macros.
	# if we add in the haskell feature of peicewise definition
	# into pink' then users could extend statements in an extreemly
	# straightforward way, by just adding a clause to the peicewise
	# definition.
	if        : (expr, statement, statement);
	while     : (expr, statement);
	return    : expr;
	statement : (if | while | return | expr);

	# expressions
	op  : string;
	lhs : expr;
	rhs : expr;
	binop-expr  : (lhs, op, rhs);
	unop-expr   : (op, rhs);
	postop-expr : (lhs, op, rhs);
	var  : (name, type, expr);
	expr : (binop-expr | unop-expr | postop-expr | var | value);
		
	# compiler directives
	import-list : list(name);
	export-list : list(name);
	root : name;
	directives : (import-list, export-list, root);

	# 
	module : (directives, symbol-table, function-table);
}

# now the programmer needs a way of assigning
# attributes to graphemes, to then use these attributes
# to define the semantic meaning of the language. (empty rules are allowed,
# it means nothing will occur.)  

# <program> is the root of this grammar
# {} define the attributes of the symbol, where
# {} occuring before the equals defines the state of the
#    symbol
# {} occuring after each production defines the sequence
#    of actions that occur after the production has matched.
#    a set of pseudo-variables starting with %% for the
#    lhs symbol's state, and a symbol for each number from [%0..%n] 
#    where n is the number of symbols occuring in the associated
#    production.

# for this first production i will state directly the intention of each statement
# just for semantic clarity, (mostly because the concrete syntax is subject to change
# at this stage of the design.)
# so: a program is defined by a module.
# at this stage all programs are single files (it's v1)
<program> { module } # == <program> { module : (directives, symbol-table, function-table) }

# a program can be constructed from a list of module declarations,
# ended by the EOF character.
	:= *(<module-declaration>) EOF {

		# we construct a module from the list of productions and bind that
		# to the root state.
		%%  <- module (%1);

		# we have to infer the types of the module, because we allow
		# eliding the typename from declarations syntactically (but not
		# semantically) so this step is to ensure that we know the type of
		# each name in the program. because there is no binding action
		# we -must- assume that infer_types is modifying the passed argument.
		# infer_types() must be defined as an action, not a function.
		infer_types(%%);

		# this step is less pinned down for me right now. the intermediate
		# representation is something that i don't have a clear idea of yet.
		# it's hard to justify some structure that is too different from
		# just using the AST directly, because the AST is already there.
		IR  <- generate-IR (%%);

		# so type_checking definitely needs to occur, and i am sure some
		# more semantic passes need to be defined, and i know they all need
		# to be defined around the Intermediate Representation.
		# (I am leaning more and more to using LLVM as the IR, because they
		# can already output all the code, but part of this project was learning
		# how to write that code myself, but all the work has already been done.
		# IDK, its a toss up right now.)
		type_check(IR);

		# this step takes the fully understood and optimized IR and converts it
		# to the target language.
		asm <- convert_to_assembly(IR);

		# this step probably calls an assembler, but it may be hand-rolled at some point.
		exe <- assemble(asm); 

		# this step is very neccessary.
		write_executable(exe, output);
	}

<module-declaration> { compiler-directive | declaration |  function }
	:= <comment>			 {}
	| <compiler-directive>   { %% <- %1; }
	| <function-declaration> { %% <- %1; }
	| <variable-declaration> { %% <- %1; }

<comment> := '#' *(_) <EOL>
# a haskell like '_'; meaning 'anything'

<compiler-directive> { compiler-directive }  
	:=  'root' <identifier> ';'		 { %% <- %2; }
	| 'import' <identifier-list> ';' { %% <- %2; }
	| 'export' <identifier-list> ';' { %% <- %2; }

# macro from observation
# <*-list> := <*> *(',' <*>) { %% <- create list(*); append(%%, %1); for (it in %3) append(%%, it); }

<identifier-list> { ids } 
	:= <identifier> *(',' <identifier>) {
		append(%%, %0); 
		for (it in *) append(%%, it); 
	}

<function-declaration> { function } 
	:= 'fn' <identifier> <function-type> <function-body> {
		%% <- function(%2, %3, %4);
	}
						  
<function-type> { (argument-list, return-list) } 
	:= <arg-list> '->' ?(<type-list>) { 
		%% <- (%1, %3); 
	}

<arg-list> { argument-list } 
	:= '(' <arg> *(',' <arg>) ')' {
		%% <- list(%2);
		for (it in %3) append (%%, it);
	}

<type-list> { return-list }  
	:= '(' <type> *(',' <type>) ')' {
		append(%%, %2);
		for (it in %3) append (%%, it);
	}

<arg> { arg } 
	:= <identifier> ':' <type> { 
		%% <- arg(%1, %2); 
	}

<function-body> { scope } 
	:= <scope> {
		%% <- scope(%1);
	}

<scope> { scope }
	:= '{' *(<variable-declaration> | <statement>) '}' {
		%% <- scope(%2);
	}

<variable-declaration> { declaration } 
	:= <identifier> ':' <type> ?('=' <initializer>) ';' {
		%% <- if (%4) then declaration(%1, ':=', %3, %4)
				      else declaration($1, $2, %3);
	} 
	| <identifier> ('::' | ':=') <initializer> ';' {
		%% <- declaration (%1, %2, %3);
	}

<type> { type }  
	:= 'int' { %% <- INT; } 
	| 'real' { %% <- REAL; } 
	| 'text' { %% <- TEXT; } 
	| 'bool' { %% <- BOOL; } 

<initializer> { expr } 
	:= <expression> {
		%% <- %1;
	}

<statement> { statement } 
	:= <if>			{ %% <- %1; }
	| <while>		{ %% <- %1; }
	| <return>		{ %% <- %1; }
	| <scope>		{ %% <- %1; }
	| <expression>  { %% <- %1; }

<if> { if }	
	:= 'if' '(' <expression> ')' <statement> ?('else' <statement>) {
		%% <- if(%3, %5, %6);
	}
		
<while> { while } 
	:= 'while' '(' <expression> ')' <statement> {
		%% <- while(%3, %5);
	}

<return> { return } 
	:= 'return' <expression> {
		%% <- return(%2);
	}

<expression> { expr } 
	:= <expr> ';' {
		%% <- expr(%1);
	}

#{
	taking straight from Yacc/Bison/Happy
	an operators precedence does not need
	to be denoted explicitly in the grammar
	rules, but is denoted by stating it
	as a property of the operator.

	%prec
	%left
	%right

	the binary operator production can work with any string of charaters
	a binary operator can be any function that looks
	like:
	fn binop-signature(lhs : type-a, rhs : type-b) -> result : type-c {
		# body
	}
	and a binary operator maybe left or right associative

	the unary operator production can work with any string of characters.
	a unary operator can be any function that looks 
	like:
	fn unop-signature(rhs : type-a) -> result : type-b {
		# body
	}
	unary operators always appear in a prefix position
	a unary operator always binds to its immediate right symbol.

	the postfix operator production needs to be defined by a 
	pair of symbols one which predicts the beginning of the operation,
	and the second ending the operation.
	a postfix operator can be any function that looks
	like:
	fn postfix-signature(lhs : type-a, rhs : type-b) -> result : type-c {
		# body
	}
	a postfix operator always binds to it's immediate left symbol

	using expressions in pink, is a way of composing functions together
	in a syntax light semantically rigorous way. there will be the ability
	to overload existing operators for new types, and to declare new operators
	entirely. 

	aside: 
	maybe removing named member access in favor of positional
	access, and pattern matching would work well with the more
	functional look and feel to the language. if a sum type
	can be split over a tuple into names, instead of saying

	sumtype.member <- xx

	we can say:  
	sumtype -> (mem1, mem2)
	   mem1 <- xx

	or

	sumtype[0] <- xx

	we can split a sum type over a tuple in a switch context
	switch (sumtype) {
	(val1, val2):

	(val3, val4):

	(val5, val6):

	default:

	}
#}

<expr> { expr }
	:= <numeric-literal>    { %% <- number(%1);        } 
	| <unop> <expr>         { %% <- unop(%1, %2);      }
	| <expr> <binop> <expr> { %% <- binop(%1, %2, %3); }
	| <expr> +(<postop>)    { %% <- postop(%1, %2);    }
	| '(' <expr> ')'        { %% <- expr(%2);          }
#   | <tuple-literal>       { %% <- tuple(%1);         }

# <tuple-literal> := '[' <identifier-list> ']' { %% <- %2; }

#{ 
precedence table:
	lowest
	assignation
	boolean eq, neq
	boolean less, less-than, greater, greater-than
	boolean or
	boolean xor
	boolean and
	bitwise or
	bitwise xor
	bitwise and
	bitwise lshift, rshift
	arithmetic add, sub
	arithmetic mult, div, mod
	procedure evaluation
	highest 
#}
# some complicated, valid expressions that should be 
# able to be parsed given this BNF grammar
# a, b, c, d = f(g + k, h - J(q), i, j);
# a = 0, b = "sometext", c = j + k, g = F() - G(P);

<expr> := <assignment-expr>
		| <expr> ',' <assignment-expr>

<assignment-expr> := <logical-exuality-expr>
				   | <unary-expr> <assignment-operator> <assignment-expr>

<logical-equality-expr> := <logical-relation-expr>
						 | <logical-equality-expr> '==' <logical-relation-expr>
						 | <logical-equality-expr> '!=' <logical-relation-expr>

<logical-relation-expr> := <logical-or-expr>
						 | <logical-relation-expr> '<' <logical-or-expr>
						 | <logical-relation-expr> '>' <logical-or-expr>
						 | <logical-relation-expr> '<=' <logical-or-expr>
						 | <logical-relation-expr> '>=' <logical-or-expr>

<logical-or-expr := <logical-xor-expr>
				  | <logical-or-expr> '|' <logical-xor-expr>

<logical-xor-expr> := <logical-and-expr>
					| <logical-xor-expr> '^' <logical-and-expr>

<logical-and-expr> := <logical-not-expr>
					| <logical-and-expr> '&' <bitwise-or-expr>

<bitwise-or-expr>  := <bitwise-xor-expr>
					| <bitwise-or-expr> '||' <bitwise-xor-expr>

<bitwise-xor-expr> := <bitwise-and-expr>
					| <bitwise-xor-expr> '^^' <bitwise-end-expr>

<bitwise-and-expr> := <bitwise-not-expr>
					| <bitwise-and-expr> '&&' <bitwise-shift-expr>

<bitwise-shift-expr> := <arithmetic-additive-expr>
					  | <bitwise-shift-expr> '<<' <arithmetic-additive-expr>
					  | <bitwise-shift-expr> '>>' <arithmetic-additive-expr>

<arithmetic-additive-expr> := <arithmetic-multiplicative-expr>
							| <arithmetic-additive-expr> '+' <arithmetic-multiplicative-expr>
							| <arithmetic-additive-expr> '-' <arithmetic-multiplicative-expr>

<arithmetic-multiplicative-expr> := <typecast-expr>
								  | <arithmetic-multiplicative-expr> '*' <postfix-expr>
								  | <arithmetic-multiplicative-expr> '/' <postfix-expr>
								  | <arithmetic-multiplicative-expr> '%' <postfix-expr>

<postfix-expr> := <primary-expr>
				| <postfix-expr> <argument-list>

<primary-expr> := <identifier>
				| <literal>
				| <unary-expr>
				| '(' (<expr>)? ')'
				| ')'
				| ';'

<unary-expr> := <unop> <primary-expr>

