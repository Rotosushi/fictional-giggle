





# what are we talking about

variant 1:
this is some sample syntax

variant 2:
this is another considered syntax, which is assumed to 
imply the same semantics exactly as the syntax above.


# --- the basic language ---

# variables:
# variables in pink can have their type xor initializer elided
#	if the type is elided, it must be inferrable.
#	if the value is elided, it is default initialized. (unlness initialization is suppressed.)
# variables can be locally or globally scoped
# variables are lexically scoped

var some-name : type-name = some-value;


# functions:
# functions are typed by their name + argument list + return value
# for a function call to be valid, the types of it's arguments
#	must match the number and position of the named function.
# functions can have the same name, as long as their argument lists differ
#	by either type, or number. (this is known as 'ad-hoc' polymorphism)
# functions come with their very own local scope, which only
# inherits the file scoped symbols, and any symbols explicitly required by the programmer.
# at the end of a scope, any name defined in that scope is undefined.
# variables in a local scope will shadow the names of global variables,
# and variables in pseudo-scopes will shadow the names of any local variables on top of this.


fn some-name (arg1 : type, arg2 : type) -> return-value 
{
	the-body-in-which-statements-are-executed;
}


# functions can also be parametrically polymorphic. 
#	 in which case the type of one of the parameters,
#	has been elided and replaced with a type-polymorph.
#	this type-polymorph stands in place of the type
#   of the parameter wherever it appears in the body
#	of the function. when a user trys to subsequently
#	call a polymorphic function, the compiler uses
#	the call's parameter types to infer the type-polymorphs type
#	throughout the function, and if then generates a valid version 
#	of that function, acting on the passed in type.
#	this only works if the type the callee passes in
#	has the syntax & semantics the function trys to
#	apply to that type.
#	in order to define the kinds of syntax and semantics
#	a type can have, without refferring to a specific type,
#	the language will also have type aspects.
#	(not to be confused with aspects, from aspect oriented programming.)


# statements
# statements are the rest of the functionality of the language.
# the basic statements are if-else if-else conditionals, while loops,
# and affix expressions. where you can compose function calls in
# pre-, in-, and post-fix position.

# we choose between semantics using conditionals

 if (some-condition-is-true) ... else if (some-other-condition) ... else ...

# the ... can be any other statement

# we iterate over semantics using while loops

 while (some-condition-is-true) ...

# we preform function calls with affix expressions

 func(arg, value) + literal == func2(arg2);

# affix expressions are ended with a semicolon.
# affix expressions are composed of prefix operations,
# infix operations, and postfix operations.
# operations are subtly different than normal function calls.
# they are functions which have a very particular parametric form.
# they also have names which are composed of more abstract symbols,
#	and not of alphanumeric characters.
# the header to a prefix operation must have the form:

 prefix-op "symbol" (arg1: $type-polymorph) -> ret1 : $another-type-polymorph {}

# prefix operators bind to their immediate right grapheme
# they expect a single argument, and return a single value
# a prefix operators symbol is what it looks like when used in affix position.

# the header to an infix operation must have the form:

 infix-op "symbol" (arg1: $type-polymorph, arg2 : $another-type-polymorph) -> ret1 : $one-more-type-polymorph {}

# infix operators bind according to their precedence
#	so the language will need some way of specifying that for new ops,
#	overloaded ops will bind with the same precedence.
# an infix operators first argument is the grapheme to it's left.
#	it's second argument is the grapheme to it's right.
# an infix operators symbol is what it looks like when used in affix position.

# a postfix operator is a special case for now, with only language operators being able
# to be defined, (but i think overloading semantics wouldn't be out of reach)
# the definition of a postfix operator will most likely need to be expressed
# as a macro, or as something deeper in the langauge, with some sense of parsing,
# to find the difference between something like
# a function call vs array access vs member access vs some user defined thing.

# Types
# a type is something that entities in the language -have-
# for variables it is the set of defined behavior on the variable
# for functions it is their arguments and returns

# a type encapsulates value.
# an integer type encapsulates the set of values that the integers could take, 
# and the set of behaviors that are valid on that type.
# the encapsulated value of a function we will consider as it's set of return values,
# and it's body.

# the language has a set of built in primitive types which map nicely onto
# much of the hardware in use today.

int, real, text, bool, bit, byte, word

# plus simple names when we want to be explicit with the size

u8/16/32/64, s8/16/32/64, f32/64

# we also need ways of constructing composite types.
# for that we start with a few composite type primitives.

[], *, Option, 

# for bulding custom composite types we use algebraic data types.

adt type-name = field			: type1 + type2 + type3
			  | alternate-field : type4 + type2 + type3;

or 

record type-name {
	field1 : type1;
	field2 : type2;
	field3 : type3;
}

union type-name {
	alt1 : type1;
	alt2 : type2;
	alt3 : type3;
}

# personally I like the affix expression version of the adt specification.
# for a few reasons; it is easier to parse, and easier to produce specifications programmatically.
# it is at least as unambiguious as the c-style record/union specification, while requiring
# dramatically less characters, especially for nested structures.



# type aspects:

aspect equality-comparable(t : $T) -> bool 
{
	if (exists(t == t)) return true;
	else return false;
}

aspect orderable(t : &T) -> bool
{
	if (exists(t < t) & equality-comparable(t)) return true;
	else return false;
}

# then one could define functions which took type aspects
# where one would specify type, and the compiler could 
# check and emit errors if the type didn't support
# the syntax and semantics.
# to actually do semantic checks, one could imagine
# more complex aspect bodies which did more
# calculation at compile-time.
# in fact, combined with compile-time interpretation,
# this could be a rather powerful language pattern.



















































#construction:
	var var-0 := 0;

	var var-1 : int;

# construct an anonymous tuple using '[,]'
# (instead of the traditional parenthized list '(,)' syntax,
# because the '(,)' syntax has an ambiguous parse in expressions.  
# it's undecidable between a sub-expression and a tuple 
# in an LL(1) restricted grammer.

	return [1, "hello"];

#abstraction:

	adt type-name = A type-1 + type-2 | B type-1 + type-3;

	fn fun-1 (arg1 : int, arg2 : int) -> bool {
		return arg1 == arg2;
	}


# with polymorphic constructors for our algebraic data types,
# (sum and product, in c respectively: struct and union)

	adt Maybe = None: Nil | Some: $SomeType

# with the associated constructors
	
	Maybe(Nil) -> Maybe(None)

	Maybe(j: $SomeType) -> Maybe(SomeType)

# then we could imagine a function that returns a maybe

	allocate(type: $SomeType) -> Maybe(Ptr(SomeType))

# one might observe this and say "well hey, all you've done
# is moved the problem of the nullptr into the type system,
# doesn't that just move the problem and not actually solve it?"
# my respose would be: well, that's not entirely right or wrong.
# yes it moves the problem, but it moves it into the realm of
# the static analysis tools of the compiler.
# which can all queue into the type of something easily,
# so it turns pointer validity from a user managed issue,
# to something that the language can build semantics around.
# it also formalizes one way of handling uninitialized memory,
# as the easy way to do it.

# if we consider something that is analagous to the void*
# the 'any' type, it is like the 'Maybe' type in that it encapsulates
# any type, but unlike the 'Maybe' type, the 'any' type isn't all that
# useful. why not you ask? well consider why we have types in the
# first place. to encapsulate behavior. when we know the type
# of a variable, we also know what the valid operations on that type are.
# if you have a container that holds anything, then what behavior can
# you rely on? none. 
# there is by definition no behavior that is valid on all.
# possible types. there are aspects of a type that are universal,
# such as the name, and the size. but behavior of the type is not something that
# all types share. however, some types do share behavior. for instance we 
# can consider the case of addition. addition makes sense when talking about
# a variety of abstractions, Integers, Real numbers, Vectors, Matricies, and more.
# but in each case, the method of addition is different. in this instance
# function overloading serves us nicely, we are able to define an operation
# called addition, and define an operator '+', and we can define
# a new function with the same name, but different parameter types and
# then through type analysis of occurances of add or '+' in the source text,
# we can correctly call each different addition function depending on the
# type of the argument. this is both intuitive and expressive.
# it gives programmers a very natural way of talking about types to rely
# on overloading, and it can improve legibility in some places.

# what if i was in different circumstances, and I was instead writing 
# a generic function which would take a less specific type?
# instead of taking an argument of a specific type, it was able to
# take arguments with types that garunteed certain semantics were valid
# upon said type. we could invoke certain constraints on the passed types
# and if they hold, we can consider the function call to be valid.
# a constraint tests some aspect of the type, therefore if
# the constraint passes the type could be said to 'posses' or 'have'
# that aspect. 

# given the previous information, we could formulate:
# I have a function which makes sense only on types which
# can be added together. (this functions operation relies upon calling
# the add function on two variables with said type)
# this semi-opaque type would not actually care what the name of
# any given type passed was, it would only care that the function
# add(a: type-name, b: type-name) -> type-name was defined in the
# current context.
# if you consider this carefully you might say that this is
# semantically equivalent to having a virtual base-class between
# all types which have add supported. which is true to a point.
# the main differences are that the constraints can be any valid pink
# statement, and are not only limited to simple does this function exist.
# and that one does not have to modify the underlying type
# to define new constraints around the type.

# what does the syntax of a function taking a type aspect look like?

the keyword aspect then always defines a function with this signature
fn-name(t: $TypeName) -> bool 

aspect Addable (t: $Type) -> bool { 
	return Exists(t + t);
}

then we could define a function which looked like
fn convoluted-double(x: Addable) -> {
	return x + x;
}

and that would be a valid function to double any type which supported
addition semantically.

# if we consider that dynamic memory is always handled in an option type,
# it also changes the syntax around accessing dynamic memory thusly
#{
	a common pattern in C surrounding dynamic memory looks like
	
	var* my-var-ptr = (var*)malloc(sizeof(var));
	if(my-var-ptr != nullptr) {x}
	else {y}

	which means:
	allocate memory of this size, and this type
	and if you did allocate do x,
	if you couldn't allocate enough do y.

	well with the Maybe type and an allocate function
	written in a polymorphic and reflective way like {
		
		adt Maybe = None: Nil | Some: $SomeType
		
		Maybe(Nil) -> Nil

		Maybe(j: $SomeType) -> SomeType

		allocate(type: $SomeType) -> Maybe(Pointer(SomeType))
		# polymorphic because the type is deduced from the 
		# passed argument, Reflective because allocate needs
		# to know the size of the type, which relies on 
		# knowledge of the hardware.
	}

	we could imagine a syntax like {
		my-dynamic-var := allocate(my-type);
		if (my-dynamic-var) {x}
		else {y}
	}
	and it would have the same meaning as the C statements above
	with one difference, being that my-dynamic-var has the type
	Maybe(Pointer(SomeType())) not Pointer(SomeType())
	and the if conditional would know that by default when handed
	an option type, it uses the None/Nil option as the else case.
	while loops could have the same default. 

#}

# first class functions. c already has function pointers,
# what if we just extend function pointer semantics and change the
# syntax such that we can make functions first-class
# so maybe the function type could be ->?

# in a function definition:

fn first-class(p: int, p: int, fun(int, int) -> int) -> int {}

# we could imagine a definition of what could be a function argument
# in a function definition to include this lambda syntax
