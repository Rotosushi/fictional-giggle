

so, we will be using LLVM as the backend
to simplify implementation.

to first get up and running
we need to think about what
the assembly representation
needs to include and look
like, in order to plan somewhat
the organization and structure
of the "translator" class.

we can define the Typechecker,
the Evaluator, and the Translator
classes as visitors to the Ast.
in order for the subroutines
to do their work upon the different
types of Node, the class will be an
overload set of procedures, each having
a unique body to deal with each node,
and the node to be processed is passed
by argument, which allows us to define
the visitors to be mutually recursive,
and apply the right procedure to the right
runtime type of the Ast nodes being
processed. with the dispatch being
taken care of by the compiler, instead
of having to write the switch statement
ourselves. (as we did in the c implementation)

this is a design which takes poor advantage
of cpp's polymorphism.

in order to actually make use of object oriented
polymorphism, the objects which are being dispatched
over must themselves be descriptions of the source
text. the Ast as it were, has been subsumed by the
Entities themselves. this follows with Object Oriented
style, in that now, instead of having to define a
set of procedures taking each kind of Ast node,
each Ast node is instead associated with it's
typing and evaluation procedures directly. and
the dispatch is handled by the single argument
of polymorphic type allowed in cpp.
to emulate the same behavior in c, we could store
a constant function pointer within the
Ast, and always call that procedure when typing
or evaluating that specific Ast. thus each node
would correctly call the right procedure. and
by keeping the arguments to pointers, we could
work to maintain some semblance of generality.
also, we are trying a shared_ptr approach to the
implementation instead of doing the work required
with unique_ptr.

so,
getting to LLVM,
we need to start with
what do we need to be producing,
and how do we produce it?
(some eternal programming questions)

we (eventually) need to produce separate
compilation units, the contents of each
being the translated contents of each
source file that was parsed and
translated by the compiler.
this is after we have modules however.

to start, we consider translation from the
perspective of the interpretive environment.
namely, a procedure which takes an Abstract
syntax tree, and produces the correct LLVM
intermediate Representation which has the
same semantics as the given syntax.
this is the primitive operation upon which
we act to build up the assembly translation
of all the source text.

if we consider an interpretive
environment which can translate pieces of
itself into LLVM. it is then, that we can
consider the processes of compilation.
as a coordination of the translation
process, such that we end up with a single
executable, which exhibits the semantics of
all the source text. we combine two source
files, expecting to find no two identical
declarations, (with a small exception in
procedure overloading),
we will eventually consider modules,
which control the visibility of their definitions
and thus control the visibility of names
between modules. additionally, we will have
some form of object orientation, given that
objects are a implementation of existential
types, and existential types give us interfaces,
and objects. we need not take all the same subtleties
and constraints. (but we may need to take and
understand some, those which are more fundamental
to the problem, than those that are fundamental to
the implementation within other languages.)

simply put, names need
to uniquely identify entites within the
program, we would say global value names need
to be distinct from one another, as we cannot
treat a global constant name as two separate
anythings. but we can allow procedures to share
names as long they differ by number or type of
arguments. (commonly called overloading)
we can allow name shadowing, by allowing a name
to be defined if it doesn't exist within the
local scope. instead of forcing all names
to be unique across all scopes within the
program. (this would be super inconvenient
for programmers however)
however, name shadowing introduces an issue,
how do we then refer to either name explicitly,
such that i can access either the local name
or the shadowed name should i desire. it would
seem that we lose the ability to access the
outer name once the inner name is defined.
a solution which is extensible is namespaces,
we could say, global_scope::global_name
a-la cpp. given this though, what is to stop
an upper scope from accessing some procedures
local-value? this just doesn't make sense and
shouldn't be allowed. the only names which
can be accessed which are technically 'local'
variables are the data-members of records, unions,
and pointers.
we can and should allow for an inner scope to
access names of outer scopes. this is well defined
in all situations, the procedure call is the
downward name boundary. (as in, names in the local
namespace stop being visible in the new scope,
even though it is technically a 'lower' scope.)
there is no upwards name boundary however,
every procedure will have access to module local variables
and global variables. or if it is a procedure local
lambda, then it will have visibility of the surrounding
scope. (formal procedures never have this 'dynamic scope')
this is because we can be sure that a lambda defined
and applied on within the scope of another procedure
will always exist in the correct circumstances such
that the dynamic names will be alive. this can turn out
not to be the case if the lambda is returned as the result
of evaluating the procedure. in this case, the names
that are used 'dynamically' within the lamdba, must be
captured by-value on the heap, and a pointer to this
structure is stored alongside a pointer to the
definition of the returned procedure. then, that procedure
can be called at a later point, and the dynamic values
are still alive in the program.

starting from a set of
source files, and a function which can
translate any given Ast into LLVM IR.
we consider the processes of picking up
definitions until we are out of source text
and then translating the final set of
knowable definitions into the final executable.
(this is modulo dynamic linking.)

{ source-file : { source-text }} ...
{ module : { IR }} ...
{ executable }


so, we consider the translation of each of our component
language entities.

starting with Types.
we can type Integers as having type IntegerType
with some specified bitwidth

we can represent bool types as having
IntegerType with bitwidth one.

we can represent reals as having Type
float. but llvm declares no subclass
for floats.




starting with expressions, and thusly, constants.
in LLVM constants have their own class for representation.

#include "llvm/IR/Constants.h"

we can translate literal integers that we see directly
into objects of type
  ConstantInt.
there are constructors which take strings even.

we can similarly use more of these classes for
constants of other varieties.

ConstantFP (for Real literals)

ConstantArray
ConstantVector
ConstantStruct

ConstantExpr (for expressions which can be performed at compile time)


GlobalValue is the type of functions (their address specifically)
 and global variables, and is a subclass of Constant




















----------------------------------------------
